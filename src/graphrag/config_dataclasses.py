"""
GraphRAG ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ - í™•ì¥ëœ dataclass êµ¬ì¡°
YAML íŒŒì¼ êµ¬ì¡°ì— ì™„ì „íˆ ë§¤ì¹­ë˜ëŠ” dataclassë“¤
"""

import os
import json
import yaml
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, field
from enum import Enum

# ì„¤ì • íŒŒì¼ ë¡œë”©
try:
    from dotenv import load_dotenv

    _dotenv_available = True
except ImportError:
    _dotenv_available = False

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class ConfigSource(Enum):
    """ì„¤ì • ì†ŒìŠ¤ ìš°ì„ ìˆœìœ„"""

    DEFAULT = 1
    CONFIG_FILE = 2
    ENVIRONMENT = 3


# ============================================================================
# LLM ê´€ë ¨ ì„¤ì •ë“¤
# ============================================================================


@dataclass
class HuggingFaceLocalConfig:
    """HuggingFace ë¡œì»¬ ëª¨ë¸ ì„¤ì •"""

    model_path: str = "/DATA/MODELS/models--meta-llama--Llama-3.1-8B-Instruct"
    max_new_tokens: int = 2048
    do_sample: bool = True
    top_p: float = 0.9
    top_k: int = 50
    repetition_penalty: float = 1.1
    device_map: str = "auto"
    torch_dtype: str = "bfloat16"
    trust_remote_code: bool = True
    batch_size: int = 32


@dataclass
class OpenAIConfig:
    """OpenAI API ì„¤ì •"""

    api_key: str = "${OPENAI_API_KEY}"
    model_name: str = "gpt-4o"
    timeout: int = 60


@dataclass
class AnthropicConfig:
    """Anthropic API ì„¤ì •"""

    api_key: str = "${ANTHROPIC_API_KEY}"
    model_name: str = "claude-3-5-sonnet"
    timeout: int = 60


@dataclass
class HuggingFaceAPIConfig:
    """HuggingFace API ì„¤ì •"""

    model_name: str = "microsoft/DialoGPT-large"
    api_key: str = "${HUGGINGFACE_API_KEY}"


@dataclass
class LLMConfig:
    """LLM í†µí•© ì„¤ì •"""

    provider: str = "huggingface_local"
    temperature: float = 0.1

    # ê° í”„ë¡œë°”ì´ë”ë³„ ì¤‘ì²© ì„¤ì •
    huggingface_local: HuggingFaceLocalConfig = field(
        default_factory=HuggingFaceLocalConfig
    )
    openai: OpenAIConfig = field(default_factory=OpenAIConfig)
    anthropic: AnthropicConfig = field(default_factory=AnthropicConfig)
    huggingface_api: HuggingFaceAPIConfig = field(default_factory=HuggingFaceAPIConfig)


# ============================================================================
# ì„ë² ë”© ê´€ë ¨ ì„¤ì •ë“¤
# ============================================================================


@dataclass
class SentenceTransformersConfig:
    """SentenceTransformers ì„¤ì •"""

    model_name: str = "paraphrase-multilingual-mpnet-base-v2"
    device: str = "auto"
    batch_size: int = 32
    cache_dir: str = "./cache/embeddings"


@dataclass
class EmbeddingsConfig:
    """ì„ë² ë”© ì„¤ì • (YAMLì˜ embeddings í‚¤ì— ëŒ€ì‘)"""

    model_type: str = "sentence-transformers"
    save_directory: str = "./data/processed/vector_store/embeddings"

    sentence_transformers: SentenceTransformersConfig = field(
        default_factory=SentenceTransformersConfig
    )


# ============================================================================
# ë²¡í„° ì €ì¥ì†Œ ê´€ë ¨ ì„¤ì •ë“¤
# ============================================================================


@dataclass
class FAISSConfig:
    """FAISS ë²¡í„° ì €ì¥ì†Œ ì„¤ì •"""

    persist_directory: str = "./data/processed/vector_store/faiss"
    index_type: str = "flat"
    distance_metric: str = "cosine"
    use_gpu: bool = False
    gpu_id: int = 0
    gpu_memory_fraction: float = 0.5


@dataclass
class ChromaDBConfig:
    """ChromaDB ë²¡í„° ì €ì¥ì†Œ ì„¤ì •"""

    persist_directory: str = "./data/processed/vector_store/chromadb"
    collection_name: str = "graphrag_embeddings"
    distance_metric: str = "cosine"


@dataclass
class SimpleStoreConfig:
    """Simple ë²¡í„° ì €ì¥ì†Œ ì„¤ì •"""

    persist_directory: str = "./data/processed/vector_store/simple"


@dataclass
class VectorStoreConfig:
    """ë²¡í„° ì €ì¥ì†Œ í†µí•© ì„¤ì •"""

    store_type: str = "faiss"
    batch_size: int = 128
    persist_directory: str = "./data/processed/vector_store"

    # ê° ì €ì¥ì†Œë³„ ì¤‘ì²© ì„¤ì •
    faiss: FAISSConfig = field(default_factory=FAISSConfig)
    chromadb: ChromaDBConfig = field(default_factory=ChromaDBConfig)
    simple: SimpleStoreConfig = field(default_factory=SimpleStoreConfig)


# ============================================================================
# ê·¸ë˜í”„ ì²˜ë¦¬ ê´€ë ¨ ì„¤ì •ë“¤
# ============================================================================


@dataclass
class NodeEmbeddingsConfig:
    """ë…¸ë“œ ì„ë² ë”© ì„¤ì •"""

    max_text_length: int = 512
    batch_size: int = 32
    cache_embeddings: bool = True
    cache_dir: str = "./cache/embeddings"
    output_directory: str = "./data/processed/vector_store/embeddings"


@dataclass
class SubgraphExtractionConfig:
    """ì„œë¸Œê·¸ë˜í”„ ì¶”ì¶œ ì„¤ì •"""

    max_nodes: int = 300
    max_edges: int = 800
    max_hops: int = 3
    initial_top_k: int = 25
    similarity_threshold: float = 0.5
    expansion_factor: float = 2.5


@dataclass
class ContextSerializationConfig:
    """ì»¨í…ìŠ¤íŠ¸ ì§ë ¬í™” ì„¤ì •"""

    max_tokens: int = 8000
    format_style: str = "structured"
    language: str = "mixed"
    include_statistics: bool = True
    include_relationships: bool = True


@dataclass
class GraphProcessingConfig:
    """ê·¸ë˜í”„ ì²˜ë¦¬ í†µí•© ì„¤ì •"""

    node_embeddings: NodeEmbeddingsConfig = field(default_factory=NodeEmbeddingsConfig)
    subgraph_extraction: SubgraphExtractionConfig = field(
        default_factory=SubgraphExtractionConfig
    )
    context_serialization: ContextSerializationConfig = field(
        default_factory=ContextSerializationConfig
    )


# ============================================================================
# í•˜ë“œì›¨ì–´ ë° ì„±ëŠ¥ ì„¤ì •ë“¤
# ============================================================================


@dataclass
class HardwareConfig:
    """í•˜ë“œì›¨ì–´ ìµœì í™” ì„¤ì •"""

    use_gpu: bool = True
    gpu_memory_fraction: float = 0.7
    mixed_precision: bool = True
    cpu_threads: int = 8
    enable_gradient_checkpointing: bool = True
    enable_cpu_offload: bool = False


@dataclass
class PerformanceConfig:
    """ì„±ëŠ¥ ìµœì í™” ì„¤ì •"""

    enable_parallel: bool = True
    max_workers: int = 4
    enable_caching: bool = True
    cache_size_limit: str = "8GB"
    batch_processing: bool = True
    memory_limit: str = "16GB"
    enable_flash_attention: bool = True
    enable_model_parallelism: bool = True


# ============================================================================
# ì¿¼ë¦¬ ë¶„ì„ ì„¤ì •ë“¤
# ============================================================================


@dataclass
class ComplexityThresholds:
    """ë³µì¡ë„ ì„ê³„ê°’ ì„¤ì •"""

    simple_max: float = 0.3
    medium_max: float = 0.6
    complex_max: float = 0.8


@dataclass
class LanguageDetectionConfig:
    """ì–¸ì–´ ê°ì§€ ì„¤ì •"""

    default_language: str = "ko"
    supported_languages: List[str] = field(default_factory=lambda: ["ko", "en"])


@dataclass
class QueryTimeouts:
    """ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ ì„¤ì •"""

    simple: int = 20
    medium: int = 45
    complex: int = 120
    exploratory: int = 240


@dataclass
class QueryAnalysisConfig:
    """ì¿¼ë¦¬ ë¶„ì„ ì„¤ì •"""

    complexity_thresholds: ComplexityThresholds = field(
        default_factory=ComplexityThresholds
    )
    language_detection: LanguageDetectionConfig = field(
        default_factory=LanguageDetectionConfig
    )
    timeouts: QueryTimeouts = field(default_factory=QueryTimeouts)


# ============================================================================
# ê²½ë¡œ ê´€ë¦¬ ì„¤ì •ë“¤
# ============================================================================


@dataclass
class VectorStorePathsConfig:
    """ë²¡í„° ì €ì¥ì†Œ ê²½ë¡œë“¤"""

    embeddings: str = "./data/processed/vector_store/embeddings"
    faiss: str = "./data/processed/vector_store/faiss"
    chromadb: str = "./data/processed/vector_store/chromadb"
    simple: str = "./data/processed/vector_store/simple"


@dataclass
class PathsConfig:
    """ê²½ë¡œ ì„¤ì • í†µí•©"""

    data_dir: str = "./data"
    processed_dir: str = "./data/processed"
    unified_graph: str = "./data/processed/graphs/unified/unified_knowledge_graph.json"
    individual_graphs_dir: str = "./data/processed/graphs"
    vector_store_root: str = "./data/processed/vector_store"
    cache_dir: str = "./cache"
    embeddings_cache: str = "./cache/embeddings"
    query_cache: str = "./cache/queries"
    logs_dir: str = "./logs"
    models_dir: str = "/DATA/MODELS"

    # ë²¡í„° ì €ì¥ì†Œ í•˜ìœ„ êµ¬ì¡°
    vector_store: VectorStorePathsConfig = field(default_factory=VectorStorePathsConfig)


# ============================================================================
# ë¡œê¹… ì„¤ì •ë“¤
# ============================================================================


@dataclass
class FileLoggingConfig:
    """íŒŒì¼ ë¡œê¹… ì„¤ì •"""

    enabled: bool = True
    log_file: str = "./logs/graphrag.log"
    max_size: str = "50MB"
    backup_count: int = 5


@dataclass
class ConsoleLoggingConfig:
    """ì½˜ì†” ë¡œê¹… ì„¤ì •"""

    enabled: bool = True
    colored: bool = True


@dataclass
class LoggingConfig:
    """ë¡œê¹… í†µí•© ì„¤ì •"""

    level: str = "INFO"
    format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file_logging: FileLoggingConfig = field(default_factory=FileLoggingConfig)
    console_logging: ConsoleLoggingConfig = field(default_factory=ConsoleLoggingConfig)


# ============================================================================
# ê°œë°œ ë° ì„œë²„ ì„¤ì •ë“¤
# ============================================================================


@dataclass
class DevelopmentConfig:
    """ê°œë°œ ì„¤ì •"""

    debug_mode: bool = False
    test_mode: bool = False
    sample_data_only: bool = False
    max_test_nodes: int = 200
    enable_profiling: bool = True


@dataclass
class ServerConfig:
    """ì„œë²„ í™˜ê²½ ì„¤ì •"""

    preload_models: bool = True
    model_cache_size: int = 2
    auto_cleanup: bool = True
    cleanup_interval: int = 3600
    restrict_model_access: bool = True


# ============================================================================
# ê¸°ì¡´ ë‹¨ìˆœ ì„¤ì •ë“¤ (í˜¸í™˜ì„± ìœ ì§€)
# ============================================================================


@dataclass
class GraphConfig:
    """ê·¸ë˜í”„ ì„¤ì • (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""

    unified_graph_path: str = (
        "./data/processed/graphs/unified/unified_knowledge_graph.json"
    )
    vector_store_path: str = "./data/processed/vector_store"
    graphs_directory: str = "./data/processed/graphs"
    cache_enabled: bool = True
    cache_ttl_hours: int = 24


@dataclass
class QAConfig:
    """QA ì²´ì¸ ì„¤ì •"""

    chain_type: str = "retrieval_qa"
    max_docs: int = 10
    min_relevance_score: float = 0.3
    return_source_documents: bool = True
    enable_memory: bool = False
    memory_type: str = "buffer"
    max_memory_tokens: int = 4000


@dataclass
class SystemConfig:
    """ì‹œìŠ¤í…œ ì„¤ì • (ê¸°ë³¸)"""

    log_level: str = "INFO"
    verbose: bool = False
    parallel_processing: bool = True
    max_workers: int = 4
    temp_directory: str = "./tmp"
    enable_monitoring: bool = False


# ============================================================================
# ë©”ì¸ ì„¤ì • í´ë˜ìŠ¤
# ============================================================================


@dataclass
class GraphRAGConfig:
    """GraphRAG ì „ì²´ ì„¤ì • - YAML êµ¬ì¡°ì— ì™„ì „ ë§¤ì¹­"""

    # ë©”ì¸ ì„¤ì • ì„¹ì…˜ë“¤
    llm: LLMConfig = field(default_factory=LLMConfig)
    embeddings: EmbeddingsConfig = field(default_factory=EmbeddingsConfig)
    vector_store: VectorStoreConfig = field(default_factory=VectorStoreConfig)
    graph_processing: GraphProcessingConfig = field(
        default_factory=GraphProcessingConfig
    )
    hardware: HardwareConfig = field(default_factory=HardwareConfig)
    performance: PerformanceConfig = field(default_factory=PerformanceConfig)
    query_analysis: QueryAnalysisConfig = field(default_factory=QueryAnalysisConfig)
    paths: PathsConfig = field(default_factory=PathsConfig)
    logging: LoggingConfig = field(default_factory=LoggingConfig)
    development: DevelopmentConfig = field(default_factory=DevelopmentConfig)
    server: ServerConfig = field(default_factory=ServerConfig)

    # ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€ìš©
    graph: GraphConfig = field(default_factory=GraphConfig)
    qa: QAConfig = field(default_factory=QAConfig)
    system: SystemConfig = field(default_factory=SystemConfig)

    # ë©”íƒ€ë°ì´í„°
    version: str = "1.0.0"
    config_source: ConfigSource = ConfigSource.DEFAULT
    last_updated: Optional[str] = None


def main():
    """dataclass êµ¬ì¡° í…ŒìŠ¤íŠ¸"""

    print("ğŸ§ª Testing expanded dataclass structure...")

    try:
        # ê¸°ë³¸ ì„¤ì • ìƒì„±
        config = GraphRAGConfig()

        # ì¤‘ì²© êµ¬ì¡° ì ‘ê·¼ í…ŒìŠ¤íŠ¸
        print(f"âœ… LLM Provider: {config.llm.provider}")
        print(f"âœ… HuggingFace Model Path: {config.llm.huggingface_local.model_path}")
        print(f"âœ… Vector Store Type: {config.vector_store.store_type}")
        print(f"âœ… FAISS Directory: {config.vector_store.faiss.persist_directory}")
        print(f"âœ… Embeddings Directory: {config.paths.vector_store.embeddings}")
        print(f"âœ… Log Level: {config.logging.level}")

        # YAMLê³¼ ë§¤ì¹­ë˜ëŠ” êµ¬ì¡°ì¸ì§€ í™•ì¸
        yaml_sections = [
            "llm",
            "embeddings",
            "vector_store",
            "graph_processing",
            "hardware",
            "performance",
            "query_analysis",
            "paths",
            "logging",
            "development",
            "server",
        ]

        for section in yaml_sections:
            if hasattr(config, section):
                print(f"âœ… Section '{section}' available")
            else:
                print(f"âŒ Section '{section}' missing")

        print(f"\nâœ… Expanded dataclass structure test completed!")

    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
