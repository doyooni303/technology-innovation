"""
ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ë²¡í„° ì €ìž¥ì†Œ
Simple Memory Vector Store

FAISS/ChromaDB í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìž„ì‹œ ì†”ë£¨ì…˜
"""

import pickle
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass


@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ í´ëž˜ìŠ¤"""

    node_id: str
    node_type: str
    similarity_score: float
    text: str
    metadata: Dict[str, Any]
    embedding: Optional[np.ndarray] = None

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "node_id": self.node_id,
            "node_type": self.node_type,
            "similarity_score": self.similarity_score,
            "text": self.text,
            "metadata": self.metadata,
        }


class SimpleVectorStore:
    """ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„° ì €ìž¥ì†Œ"""

    def __init__(self, persist_directory: Optional[str] = None):
        """
        Args:
            persist_directory: ì €ìž¥ ë””ë ‰í† ë¦¬
        """
        self.persist_directory = Path(persist_directory) if persist_directory else None

        # ë©”ëª¨ë¦¬ ì €ìž¥ì†Œ
        self.embeddings = []  # List[np.ndarray]
        self.node_ids = []  # List[str]
        self.node_types = []  # List[str]
        self.texts = []  # List[str]
        self.metadatas = []  # List[Dict]

        self.is_initialized = False
        self.dimension = None
        self.total_vectors = 0

    def initialize(self, dimension: int) -> None:
        """ë²¡í„° ì €ìž¥ì†Œ ì´ˆê¸°í™”"""
        self.dimension = dimension
        self.is_initialized = True

        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹œë„
        self.load()

    def add_embeddings(
        self,
        embeddings: np.ndarray,
        node_ids: List[str],
        node_types: List[str],
        texts: List[str],
        metadatas: List[Dict[str, Any]],
    ) -> None:
        """ìž„ë² ë”© ì¶”ê°€"""
        if not self.is_initialized:
            raise ValueError("Vector store not initialized")

        # ë°ì´í„° ì¶”ê°€
        for i in range(len(embeddings)):
            self.embeddings.append(embeddings[i])
            self.node_ids.append(node_ids[i])
            self.node_types.append(node_types[i])
            self.texts.append(texts[i])
            self.metadatas.append(metadatas[i])

        self.total_vectors = len(self.embeddings)
        print(f"âœ… Added {len(embeddings)} embeddings to SimpleVectorStore")

    def search(
        self,
        query_embedding: np.ndarray,
        top_k: int = 10,
        node_types: Optional[List[str]] = None,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[SearchResult]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        if not self.embeddings:
            return []

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        query_norm = np.linalg.norm(query_embedding)
        if query_norm == 0:
            return []

        similarities = []
        valid_indices = []

        for i, embedding in enumerate(self.embeddings):
            # ë…¸ë“œ íƒ€ìž… í•„í„°ë§
            if node_types and self.node_types[i] not in node_types:
                continue

            # ì¶”ê°€ í•„í„° ì ìš©
            if filters and not self._apply_filters(self.metadatas[i], filters):
                continue

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            embedding_norm = np.linalg.norm(embedding)
            if embedding_norm == 0:
                similarity = 0.0
            else:
                similarity = np.dot(query_embedding, embedding) / (
                    query_norm * embedding_norm
                )

            similarities.append(similarity)
            valid_indices.append(i)

        # ìƒìœ„ kê°œ ì„ íƒ
        if not similarities:
            return []

        # ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬
        sorted_pairs = sorted(zip(similarities, valid_indices), reverse=True)
        top_pairs = sorted_pairs[:top_k]

        # ê²°ê³¼ ìƒì„±
        results = []
        for similarity, idx in top_pairs:
            result = SearchResult(
                node_id=self.node_ids[idx],
                node_type=self.node_types[idx],
                similarity_score=float(similarity),
                text=self.texts[idx],
                metadata=self.metadatas[idx],
                embedding=self.embeddings[idx],
            )
            results.append(result)

        return results

    def _apply_filters(self, metadata: Dict[str, Any], filters: Dict[str, Any]) -> bool:
        """ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©"""
        for key, value in filters.items():
            if key not in metadata:
                return False

            metadata_value = metadata[key]

            if isinstance(value, list):
                if metadata_value not in value:
                    return False
            else:
                if metadata_value != value:
                    return False

        return True

    def get_embedding(self, node_id: str) -> Optional[np.ndarray]:
        """íŠ¹ì • ë…¸ë“œ ìž„ë² ë”© ì¡°íšŒ"""
        try:
            idx = self.node_ids.index(node_id)
            return self.embeddings[idx]
        except ValueError:
            return None

    def save(self) -> None:
        """ì €ìž¥ì†Œ ì˜êµ¬ ì €ìž¥"""
        if not self.persist_directory:
            print("âš ï¸ No persist directory configured")
            return

        self.persist_directory.mkdir(parents=True, exist_ok=True)

        try:
            # ë°ì´í„° ì €ìž¥
            data = {
                "embeddings": self.embeddings,
                "node_ids": self.node_ids,
                "node_types": self.node_types,
                "texts": self.texts,
                "metadatas": self.metadatas,
                "dimension": self.dimension,
                "total_vectors": self.total_vectors,
            }

            save_file = self.persist_directory / "simple_vector_store.pkl"
            with open(save_file, "wb") as f:
                pickle.dump(data, f)

            print(f"âœ… SimpleVectorStore saved to {save_file}")

        except Exception as e:
            print(f"âŒ Failed to save SimpleVectorStore: {e}")

    def load(self) -> None:
        """ì €ìž¥ì†Œ ë¡œë“œ"""
        if not self.persist_directory:
            return

        load_file = self.persist_directory / "simple_vector_store.pkl"
        if not load_file.exists():
            return

        try:
            with open(load_file, "rb") as f:
                data = pickle.load(f)

            self.embeddings = data["embeddings"]
            self.node_ids = data["node_ids"]
            self.node_types = data["node_types"]
            self.texts = data["texts"]
            self.metadatas = data["metadatas"]
            self.dimension = data["dimension"]
            self.total_vectors = data["total_vectors"]

            print(f"âœ… SimpleVectorStore loaded: {self.total_vectors} vectors")

        except Exception as e:
            print(f"âŒ Failed to load SimpleVectorStore: {e}")


class VectorStoreManager:
    """ë²¡í„° ì €ìž¥ì†Œ í†µí•© ê´€ë¦¬ìž (ê°„ì†Œí™” ë²„ì „)"""

    def __init__(
        self,
        store_type: str = "simple",
        persist_directory: Optional[str] = None,
        collection_name: str = "graphrag_embeddings",
        **kwargs,
    ):
        """
        Args:
            store_type: ì €ìž¥ì†Œ íƒ€ìž… ("simple" ê³ ì •)
            persist_directory: ì˜êµ¬ ì €ìž¥ ë””ë ‰í† ë¦¬
            collection_name: ì»¬ë ‰ì…˜/ì¸ë±ìŠ¤ ì´ë¦„
            **kwargs: ì¶”ê°€ ì„¤ì •
        """
        self.store_type = store_type
        self.persist_directory = persist_directory
        self.collection_name = collection_name

        # ê°„ë‹¨í•œ ë²¡í„° ì €ìž¥ì†Œ ì‚¬ìš©
        self.store = SimpleVectorStore(persist_directory)

        print(f"âœ… VectorStoreManager initialized: {store_type}")

    def load_from_embeddings(self, embedding_results) -> None:
        """EmbeddingResultë¡œë¶€í„° ë²¡í„° ì €ìž¥ì†Œ êµ¬ì¶•"""

        # ì°¨ì› ê²°ì •
        first_result = next(iter(next(iter(embedding_results.values()))))
        dimension = len(first_result.embedding)

        # ì €ìž¥ì†Œ ì´ˆê¸°í™”
        self.store.initialize(dimension)

        print(f"ðŸ“š Loading embeddings into vector store...")

        # íƒ€ìž…ë³„ë¡œ ì²˜ë¦¬
        for node_type, results in embedding_results.items():
            if not results:
                continue

            print(f"ðŸ“ Processing {node_type}: {len(results)} embeddings")

            # ë°°ì¹˜ë¡œ ë³€í™˜
            embeddings = np.array([result.embedding for result in results])
            node_ids = [result.node_id for result in results]
            node_types = [result.node_type for result in results]
            texts = [result.text for result in results]
            metadatas = [result.metadata for result in results]

            # ì €ìž¥ì†Œì— ì¶”ê°€
            self.store.add_embeddings(
                embeddings=embeddings,
                node_ids=node_ids,
                node_types=node_types,
                texts=texts,
                metadatas=metadatas,
            )

        # ì €ìž¥
        self.store.save()

        total_vectors = sum(len(results) for results in embedding_results.values())
        print(f"âœ… Loaded {total_vectors} embeddings into vector store")

    def search_similar_nodes(
        self,
        query_embedding: np.ndarray,
        top_k: int = 10,
        node_types: Optional[List[str]] = None,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[SearchResult]:
        """ìœ ì‚¬ ë…¸ë“œ ê²€ìƒ‰"""
        return self.store.search(
            query_embedding=query_embedding,
            top_k=top_k,
            node_types=node_types,
            filters=filters,
        )

    def get_node_embedding(self, node_id: str) -> Optional[np.ndarray]:
        """íŠ¹ì • ë…¸ë“œ ìž„ë² ë”© ì¡°íšŒ"""
        return self.store.get_embedding(node_id)

    def get_store_info(self) -> Dict[str, Any]:
        """ì €ìž¥ì†Œ ì •ë³´ ë°˜í™˜"""
        return {
            "store_type": self.store_type,
            "total_vectors": self.store.total_vectors,
            "dimension": self.store.dimension,
            "is_initialized": self.store.is_initialized,
            "persist_directory": self.persist_directory,
            "collection_name": self.collection_name,
        }


def create_vector_store(
    store_type: str = "simple", persist_directory: Optional[str] = None, **kwargs
) -> VectorStoreManager:
    """ë²¡í„° ì €ìž¥ì†Œ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return VectorStoreManager(
        store_type=store_type, persist_directory=persist_directory, **kwargs
    )
