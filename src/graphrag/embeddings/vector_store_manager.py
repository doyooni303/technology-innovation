"""
ë²¡í„° ì €ì¥ì†Œ ê´€ë¦¬ ëª¨ë“ˆ
Vector Store Manager for GraphRAG Embeddings

ë‹¤ì–‘í•œ ë²¡í„° ì €ì¥ì†Œ ì§€ì› ë° íš¨ìœ¨ì ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰
- ChromaDB: ì˜êµ¬ ì €ì¥ì†Œ ì§€ì›
- FAISS: ê³ ì† ê²€ìƒ‰ íŠ¹í™”
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ë²¡í„° + ë©”íƒ€ë°ì´í„° í•„í„°ë§
- ë°°ì¹˜ ì—°ì‚° ë° ìºì‹± ìµœì í™”
"""

import os
import json
import pickle
import logging
import warnings
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union, Set
from dataclasses import dataclass
import numpy as np
import pandas as pd
from collections import defaultdict

# ë²¡í„° ì €ì¥ì†Œ ì˜ì¡´ì„± ì²´í¬
try:
    import chromadb
    from chromadb.config import Settings

    _chromadb_available = True
except (ImportError, RuntimeError) as e:
    _chromadb_available = False
    if "sqlite3" in str(e):
        warnings.warn(
            "ChromaDB not available due to SQLite compatibility. Using FAISS instead."
        )
    else:
        warnings.warn("ChromaDB not available. Install with: pip install chromadb")

try:
    import faiss

    _faiss_available = True
except (ImportError, AttributeError) as e:
    _faiss_available = False
    if "numpy" in str(e).lower() or "_array_api" in str(e):
        warnings.warn(
            "FAISS not available due to NumPy compatibility. Try: pip install 'numpy<2.0' faiss-cpu"
        )
    else:
        warnings.warn("FAISS not available. Install with: pip install faiss-cpu")

from .multi_node_embedder import EmbeddingResult
from .simple_vector_store import SimpleVectorStore

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ í´ë˜ìŠ¤"""

    node_id: str
    node_type: str
    similarity_score: float
    text: str
    metadata: Dict[str, Any]
    embedding: Optional[np.ndarray] = None

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "node_id": self.node_id,
            "node_type": self.node_type,
            "similarity_score": self.similarity_score,
            "text": self.text,
            "metadata": self.metadata,
        }


@dataclass
class VectorStoreConfig:
    """ë²¡í„° ì €ì¥ì†Œ ì„¤ì • - í™•ì¥ëœ ë²„ì „"""

    store_type: str  # "chroma", "faiss", "simple"
    persist_directory: Optional[str] = None
    collection_name: str = "graphrag_embeddings"
    distance_metric: str = "cosine"  # "cosine", "l2", "ip"
    index_type: str = "flat"  # "flat", "ivf", "hnsw"
    batch_size: int = 1000
    cache_size: int = 10000

    # ìƒˆë¡œìš´ ì„œë¸Œí´ë” ì§€ì› ì†ì„±ë“¤
    faiss_directory: str = ""
    chromadb_directory: str = ""
    simple_directory: str = ""

    # FAISS ê´€ë ¨ ì„¤ì •ë“¤ (ëˆ„ë½ëœ í•„ë“œë“¤ ì¶”ê°€)
    use_gpu: bool = False
    gpu_id: int = 0
    gpu_memory_fraction: float = 0.5

    def __post_init__(self):
        """ì„œë¸Œ ë””ë ‰í† ë¦¬ ìë™ ì„¤ì •"""
        if self.persist_directory:
            if not self.faiss_directory:
                self.faiss_directory = f"{self.persist_directory}/faiss"
            if not self.chromadb_directory:
                self.chromadb_directory = f"{self.persist_directory}/chromadb"
            if not self.simple_directory:
                self.simple_directory = f"{self.persist_directory}/simple"


class BaseVectorStore(ABC):
    """ë²¡í„° ì €ì¥ì†Œ ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤"""

    def __init__(self, config: VectorStoreConfig):
        self.config = config
        self.is_initialized = False
        self.dimension = None
        self.total_vectors = 0

    @abstractmethod
    def initialize(self, dimension: int) -> None:
        """ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”"""
        pass

    @abstractmethod
    def add_embeddings(
        self,
        embeddings: np.ndarray,
        node_ids: List[str],
        node_types: List[str],
        texts: List[str],
        metadatas: List[Dict[str, Any]],
    ) -> None:
        """ì„ë² ë”© ì¶”ê°€"""
        pass

    @abstractmethod
    def search(
        self,
        query_embedding: np.ndarray,
        top_k: int = 10,
        node_types: Optional[List[str]] = None,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[SearchResult]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        pass

    @abstractmethod
    def get_embedding(self, node_id: str) -> Optional[np.ndarray]:
        """íŠ¹ì • ë…¸ë“œì˜ ì„ë² ë”© ë°˜í™˜"""
        pass

    @abstractmethod
    def save(self) -> None:
        """ì €ì¥ì†Œ ì˜êµ¬ ì €ì¥"""
        pass

    @abstractmethod
    def load(self) -> None:
        """ì €ì¥ì†Œ ë¡œë“œ"""
        pass


class ChromaVectorStore(BaseVectorStore):
    """ChromaDB ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ"""

    def __init__(self, config: VectorStoreConfig):
        super().__init__(config)

        if not _chromadb_available:
            raise ImportError("ChromaDB is required but not installed")

        self.client = None
        self.collection = None

    def initialize(self, dimension: int) -> None:
        """ChromaDB ì´ˆê¸°í™”"""
        self.dimension = dimension

        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        if self.config.persist_directory:
            # ì˜êµ¬ ì €ì¥ì†Œ
            persist_path = Path(self.config.persist_directory)
            persist_path.mkdir(parents=True, exist_ok=True)

            self.client = chromadb.PersistentClient(
                path=str(persist_path),
                settings=Settings(anonymized_telemetry=False, is_persistent=True),
            )
        else:
            # ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
            self.client = chromadb.Client()

        # ê±°ë¦¬ ë©”íŠ¸ë¦­ ì„¤ì •
        distance_function = {"cosine": "cosine", "l2": "l2", "ip": "ip"}.get(
            self.config.distance_metric, "cosine"
        )

        # ì»¬ë ‰ì…˜ ìƒì„±/ë¡œë“œ
        try:
            self.collection = self.client.get_collection(
                name=self.config.collection_name
            )
            logger.info(
                f"âœ… Loaded existing ChromaDB collection: {self.config.collection_name}"
            )
        except:
            self.collection = self.client.create_collection(
                name=self.config.collection_name,
                metadata={"hnsw:space": distance_function},
            )
            logger.info(
                f"âœ… Created new ChromaDB collection: {self.config.collection_name}"
            )

        self.is_initialized = True

    def add_embeddings(
        self,
        embeddings: np.ndarray,
        node_ids: List[str],
        node_types: List[str],
        texts: List[str],
        metadatas: List[Dict[str, Any]],
    ) -> None:
        """ChromaDBì— ì„ë² ë”© ì¶”ê°€"""
        if not self.is_initialized:
            raise ValueError("Vector store not initialized")

        # ChromaDB ë©”íƒ€ë°ì´í„° í˜•íƒœë¡œ ë³€í™˜
        chroma_metadatas = []
        for i, (node_id, node_type, metadata) in enumerate(
            zip(node_ids, node_types, metadatas)
        ):
            chroma_meta = {
                "node_type": node_type,
                "text_length": len(texts[i]),
                "word_count": len(texts[i].split()),
            }

            # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ChromaDBëŠ” ê°„ë‹¨í•œ íƒ€ì…ë§Œ ì§€ì›)
            for key, value in metadata.items():
                if isinstance(value, (str, int, float, bool)):
                    chroma_meta[key] = value
                elif isinstance(value, list) and len(value) > 0:
                    if isinstance(value[0], (str, int, float)):
                        chroma_meta[f"{key}_count"] = len(value)
                        if isinstance(value[0], str):
                            chroma_meta[f"{key}_first"] = value[0][:100]  # ì²« ë²ˆì§¸ ê°’ë§Œ

            chroma_metadatas.append(chroma_meta)

        # ë°°ì¹˜ ì²˜ë¦¬
        batch_size = self.config.batch_size
        for i in range(0, len(embeddings), batch_size):
            end_idx = min(i + batch_size, len(embeddings))

            batch_embeddings = embeddings[i:end_idx].tolist()
            batch_ids = node_ids[i:end_idx]
            batch_texts = texts[i:end_idx]
            batch_metadatas = chroma_metadatas[i:end_idx]

            try:
                self.collection.add(
                    embeddings=batch_embeddings,
                    documents=batch_texts,
                    metadatas=batch_metadatas,
                    ids=batch_ids,
                )
            except Exception as e:
                logger.warning(f"Failed to add batch {i}-{end_idx}: {e}")

        self.total_vectors += len(embeddings)
        logger.info(f"âœ… Added {len(embeddings)} embeddings to ChromaDB")

    def search(
        self,
        query_embedding: np.ndarray,
        top_k: int = 10,
        node_types: Optional[List[str]] = None,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[SearchResult]:
        """ChromaDB ê²€ìƒ‰"""
        if not self.is_initialized:
            raise ValueError("Vector store not initialized")

        # í•„í„° êµ¬ì„±
        where_filter = {}
        if node_types:
            where_filter["node_type"] = {"$in": node_types}

        if filters:
            for key, value in filters.items():
                if isinstance(value, list):
                    where_filter[key] = {"$in": value}
                else:
                    where_filter[key] = value

        # ê²€ìƒ‰ ì‹¤í–‰
        try:
            results = self.collection.query(
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k,
                where=where_filter if where_filter else None,
                include=["documents", "metadatas", "distances"],
            )

            # ê²°ê³¼ ë³€í™˜
            search_results = []
            if results["ids"] and results["ids"][0]:
                for i, node_id in enumerate(results["ids"][0]):
                    similarity = (
                        1.0 - results["distances"][0][i]
                    )  # ChromaDBëŠ” ê±°ë¦¬ë¥¼ ë°˜í™˜

                    search_result = SearchResult(
                        node_id=node_id,
                        node_type=results["metadatas"][0][i].get(
                            "node_type", "unknown"
                        ),
                        similarity_score=similarity,
                        text=results["documents"][0][i],
                        metadata=results["metadatas"][0][i],
                    )
                    search_results.append(search_result)

            return search_results

        except Exception as e:
            logger.error(f"ChromaDB search failed: {e}")
            return []

    def get_embedding(self, node_id: str) -> Optional[np.ndarray]:
        """íŠ¹ì • ë…¸ë“œ ì„ë² ë”© ì¡°íšŒ"""
        try:
            result = self.collection.get(ids=[node_id], include=["embeddings"])

            if result["embeddings"] and result["embeddings"][0]:
                return np.array(result["embeddings"][0])
            return None

        except Exception as e:
            logger.warning(f"Failed to get embedding for {node_id}: {e}")
            return None

    def save(self) -> None:
        """ChromaDB ì €ì¥ (ì˜êµ¬ ì €ì¥ì†Œì¸ ê²½ìš° ìë™)"""
        if self.config.persist_directory:
            logger.info("âœ… ChromaDB automatically persisted")
        else:
            logger.warning("âš ï¸ In-memory ChromaDB cannot be persisted")

    def load(self) -> None:
        """ChromaDB ë¡œë“œ (ì´ˆê¸°í™” ì‹œ ìë™)"""
        logger.info("âœ… ChromaDB loaded during initialization")


class FAISSVectorStore(BaseVectorStore):
    """FAISS ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ"""

    def __init__(self, config: VectorStoreConfig):
        super().__init__(config)

        if not _faiss_available:
            raise ImportError("FAISS is required but not installed")

        self.index = None
        self.node_id_to_idx = {}
        self.idx_to_node_id = {}
        self.node_metadatas = {}
        self.node_texts = {}
        self.node_types = {}

        # GPU ë¦¬ì†ŒìŠ¤ ì„¤ì •
        self.gpu_resources = None
        self.use_gpu = False

    def initialize(self, dimension: int) -> None:
        """FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        self.dimension = dimension

        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            import faiss

            ngpus = faiss.get_num_gpus()
            self.use_gpu = ngpus > 0

            if self.use_gpu:
                self.gpu_resources = faiss.StandardGpuResources()
                print(f"âœ… FAISS will use GPU ({ngpus} GPUs available)")
        except:
            self.use_gpu = False
            print("âš ï¸ GPU not available, using CPU")

        # ì¸ë±ìŠ¤ íƒ€ì…ì— ë”°ë¥¸ ìƒì„±
        if self.config.index_type == "flat":
            if self.config.distance_metric == "cosine":
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ìš© (ë‚´ì )
                cpu_index = faiss.IndexFlatIP(dimension)
            else:
                # L2 ê±°ë¦¬
                cpu_index = faiss.IndexFlatL2(dimension)

        elif self.config.index_type == "ivf":
            # IVF (Inverted File) ì¸ë±ìŠ¤
            nlist = 100  # í´ëŸ¬ìŠ¤í„° ìˆ˜
            quantizer = faiss.IndexFlatL2(dimension)
            cpu_index = faiss.IndexIVFFlat(quantizer, dimension, nlist)

        elif self.config.index_type == "hnsw":
            # HNSW (Hierarchical Navigable Small World)
            cpu_index = faiss.IndexHNSWFlat(dimension, 32)
            cpu_index.hnsw.efConstruction = 40
            cpu_index.hnsw.efSearch = 16

        else:
            # ê¸°ë³¸ê°’: Flat ì¸ë±ìŠ¤
            cpu_index = faiss.IndexFlatIP(dimension)

        # GPUë¡œ ì „ì†¡ (ê°€ëŠ¥í•œ ê²½ìš°)
        if self.use_gpu and cpu_index:
            self.index = faiss.index_cpu_to_gpu(self.gpu_resources, 0, cpu_index)
        else:
            self.index = cpu_index

        self.is_initialized = True
        gpu_status = "GPU" if self.use_gpu else "CPU"
        logger.info(
            f"âœ… FAISS index initialized: {self.config.index_type}, {gpu_status}, dim={dimension}"
        )

    def add_embeddings(
        self,
        embeddings: np.ndarray,
        node_ids: List[str],
        node_types: List[str],
        texts: List[str],
        metadatas: List[Dict[str, Any]],
    ) -> None:
        """FAISSì— ì„ë² ë”© ì¶”ê°€"""
        if not self.is_initialized:
            raise ValueError("Vector store not initialized")

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ìš© ì •ê·œí™” (í•„ìš”ì‹œ)
        if self.config.distance_metric == "cosine":
            # ì„ë² ë”©ì´ ì´ë¯¸ ì •ê·œí™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
            norms = np.linalg.norm(embeddings, axis=1)
            if not np.allclose(norms, 1.0, atol=1e-6):
                embeddings = embeddings / norms[:, np.newaxis]

        # ì¸ë±ìŠ¤ í›ˆë ¨ (IVFì˜ ê²½ìš°)
        if self.config.index_type == "ivf" and not self.index.is_trained:
            logger.info("ğŸ”§ Training FAISS IVF index...")
            self.index.train(embeddings.astype(np.float32))

        # í˜„ì¬ ì¸ë±ìŠ¤ í¬ê¸°
        current_size = self.index.ntotal

        # ì¸ë±ìŠ¤ì— ì¶”ê°€
        self.index.add(embeddings.astype(np.float32))

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        for i, (node_id, node_type, text, metadata) in enumerate(
            zip(node_ids, node_types, texts, metadatas)
        ):
            idx = current_size + i
            self.node_id_to_idx[node_id] = idx
            self.idx_to_node_id[idx] = node_id
            self.node_metadatas[node_id] = metadata
            self.node_texts[node_id] = text
            self.node_types[node_id] = node_type

        self.total_vectors += len(embeddings)
        logger.info(f"âœ… Added {len(embeddings)} embeddings to FAISS index")

    def search(
        self,
        query_embedding: np.ndarray,
        top_k: int = 10,
        node_types: Optional[List[str]] = None,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[SearchResult]:
        """FAISS ê²€ìƒ‰"""
        if not self.is_initialized:
            raise ValueError("Vector store not initialized")

        # ì¿¼ë¦¬ ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ìš©)
        if self.config.distance_metric == "cosine":
            query_norm = np.linalg.norm(query_embedding)
            if query_norm > 0:
                query_embedding = query_embedding / query_norm

        # ê²€ìƒ‰ ì‹¤í–‰
        query_embedding = query_embedding.astype(np.float32).reshape(1, -1)

        # ë” ë§ì´ ê²€ìƒ‰í•œ í›„ í•„í„°ë§ (FAISSëŠ” ë©”íƒ€ë°ì´í„° í•„í„°ë§ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ)
        search_k = (
            min(top_k * 10, self.total_vectors) if node_types or filters else top_k
        )

        try:
            scores, indices = self.index.search(query_embedding, search_k)

            # ê²°ê³¼ ë³€í™˜ ë° í•„í„°ë§
            search_results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx == -1:  # ìœ íš¨í•˜ì§€ ì•Šì€ ì¸ë±ìŠ¤
                    continue

                node_id = self.idx_to_node_id.get(idx)
                if not node_id:
                    continue

                node_type = self.node_types.get(node_id, "unknown")

                # ë…¸ë“œ íƒ€ì… í•„í„°ë§
                if node_types and node_type not in node_types:
                    continue

                # ì¶”ê°€ í•„í„° ì ìš©
                if filters:
                    metadata = self.node_metadatas.get(node_id, {})
                    if not self._apply_filters(metadata, filters):
                        continue

                # ìœ ì‚¬ë„ ì ìˆ˜ ë³€í™˜
                if self.config.distance_metric == "cosine":
                    similarity = float(score)  # ë‚´ì  ê°’ (ì´ë¯¸ ì •ê·œí™”ë¨)
                else:
                    similarity = 1.0 / (1.0 + float(score))  # L2 ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜

                search_result = SearchResult(
                    node_id=node_id,
                    node_type=node_type,
                    similarity_score=similarity,
                    text=self.node_texts.get(node_id, ""),
                    metadata=self.node_metadatas.get(node_id, {}),
                )
                search_results.append(search_result)

                if len(search_results) >= top_k:
                    break

            return search_results

        except Exception as e:
            logger.error(f"FAISS search failed: {e}")
            return []

    def _apply_filters(self, metadata: Dict[str, Any], filters: Dict[str, Any]) -> bool:
        """ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©"""
        for key, value in filters.items():
            if key not in metadata:
                return False

            metadata_value = metadata[key]

            if isinstance(value, list):
                if metadata_value not in value:
                    return False
            else:
                if metadata_value != value:
                    return False

        return True

    def get_embedding(self, node_id: str) -> Optional[np.ndarray]:
        """íŠ¹ì • ë…¸ë“œ ì„ë² ë”© ì¡°íšŒ"""
        idx = self.node_id_to_idx.get(node_id)
        if idx is None:
            return None

        try:
            # FAISSì—ì„œ íŠ¹ì • ë²¡í„° ì¶”ì¶œ
            embedding = self.index.reconstruct(idx)
            return embedding
        except Exception as e:
            logger.warning(f"Failed to get embedding for {node_id}: {e}")
            return None

    def save(self) -> None:
        """FAISS ì¸ë±ìŠ¤ ì €ì¥ (GPU â†’ CPU ë³€í™˜ í¬í•¨)"""
        if not self.config.persist_directory:
            logger.warning("âš ï¸ No persist directory configured")
            return

        persist_path = Path(self.config.persist_directory)
        persist_path.mkdir(parents=True, exist_ok=True)

        try:
            # GPU ì¸ë±ìŠ¤ë¥¼ CPUë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            if self.use_gpu and self.index:
                logger.info("ğŸ”„ Converting GPU index to CPU for saving...")
                cpu_index = faiss.index_gpu_to_cpu(self.index)
            else:
                cpu_index = self.index

            # ì¸ë±ìŠ¤ ì €ì¥ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            if cpu_index is None:
                raise ValueError("No index to save")

            # FAISS ì¸ë±ìŠ¤ ì €ì¥
            index_file = persist_path / "faiss_index.bin"
            logger.info(f"ğŸ’¾ Saving FAISS index to {index_file}")
            faiss.write_index(cpu_index, str(index_file))

            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata_file = persist_path / "faiss_metadata.pkl"
            metadata = {
                "node_id_to_idx": self.node_id_to_idx,
                "idx_to_node_id": self.idx_to_node_id,
                "node_metadatas": self.node_metadatas,
                "node_texts": self.node_texts,
                "node_types": self.node_types,
                "total_vectors": self.total_vectors,
                "dimension": self.dimension,
                "config": self.config,
                "use_gpu": self.use_gpu,  # GPU ì‚¬ìš© ì—¬ë¶€ ì €ì¥
                "index_type": self.config.index_type,
            }

            with open(metadata_file, "wb") as f:
                pickle.dump(metadata, f)

            logger.info(f"âœ… FAISS index saved to {persist_path}")

        except Exception as e:
            logger.error(f"âŒ Failed to save FAISS index: {e}")
            logger.error(f"   Index type: {type(self.index)}")
            logger.error(f"   Use GPU: {self.use_gpu}")

    def load(self) -> None:
        """FAISS ì¸ë±ìŠ¤ ë¡œë“œ (GPU ë³€í™˜ í¬í•¨)"""
        if not self.config.persist_directory:
            logger.warning("âš ï¸ No persist directory configured")
            return

        persist_path = Path(self.config.persist_directory)
        index_file = persist_path / "faiss_index.bin"
        metadata_file = persist_path / "faiss_metadata.pkl"

        if not index_file.exists() or not metadata_file.exists():
            logger.info("ğŸ“‚ No existing FAISS index found")
            return

        try:
            # ë©”íƒ€ë°ì´í„° ë¨¼ì € ë¡œë“œ
            with open(metadata_file, "rb") as f:
                metadata = pickle.load(f)

            self.node_id_to_idx = metadata["node_id_to_idx"]
            self.idx_to_node_id = metadata["idx_to_node_id"]
            self.node_metadatas = metadata["node_metadatas"]
            self.node_texts = metadata["node_texts"]
            self.node_types = metadata["node_types"]
            self.total_vectors = metadata["total_vectors"]
            self.dimension = metadata["dimension"]

            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ (CPUë¡œ ë¨¼ì € ë¡œë“œ)
            logger.info(f"ğŸ“‚ Loading FAISS index from {index_file}")
            cpu_index = faiss.read_index(str(index_file))

            # GPU ì‚¬ìš©ì´ ì„¤ì •ë˜ì–´ ìˆê³  ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ ì „ì†¡
            if self.use_gpu and cpu_index:
                try:
                    logger.info("ğŸš€ Converting loaded index to GPU...")

                    # GPU ë¦¬ì†ŒìŠ¤ ì¬ì´ˆê¸°í™” (í•„ìš”ì‹œ)
                    if not self.gpu_resources:
                        self.gpu_resources = faiss.StandardGpuResources()

                    self.index = faiss.index_cpu_to_gpu(
                        self.gpu_resources, 0, cpu_index
                    )
                    logger.info("âœ… Index successfully moved to GPU")
                except Exception as gpu_error:
                    logger.warning(f"âš ï¸ Failed to move index to GPU: {gpu_error}")
                    logger.warning("ğŸ“± Using CPU index instead")
                    self.index = cpu_index
                    self.use_gpu = False
            else:
                self.index = cpu_index

            self.is_initialized = True
            logger.info(f"âœ… FAISS index loaded: {self.total_vectors} vectors")

        except Exception as e:
            logger.error(f"âŒ Failed to load FAISS index: {e}")

            # ì†ìƒëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ì œê±°
            try:
                if index_file.exists():
                    index_file.unlink()
                    logger.info("ğŸ—‘ï¸ Removed corrupted index file")
                if metadata_file.exists():
                    metadata_file.unlink()
                    logger.info("ğŸ—‘ï¸ Removed corrupted metadata file")
            except:
                pass


class VectorStoreManager:
    """ë²¡í„° ì €ì¥ì†Œ í†µí•© ê´€ë¦¬ì - ìƒˆë¡œìš´ ê²½ë¡œ êµ¬ì¡° ì§€ì›"""

    def __init__(
        self,
        store_type: str = "auto",
        persist_directory: Optional[str] = None,
        collection_name: str = "graphrag_embeddings",
        config_manager: Optional["GraphRAGConfigManager"] = None,
        **kwargs,
    ):
        """
        Args:
            store_type: ì €ì¥ì†Œ íƒ€ì… ("auto", "chroma", "faiss", "simple")
            persist_directory: ì˜êµ¬ ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
            collection_name: ì»¬ë ‰ì…˜/ì¸ë±ìŠ¤ ì´ë¦„
            config_manager: ì„¤ì • ê´€ë¦¬ì (ì œê³µì‹œ ì„¤ì • ìë™ ì ìš©)
            **kwargs: ì¶”ê°€ ì„¤ì •
        """
        self.config_manager = config_manager

        # ì„¤ì • ê´€ë¦¬ìê°€ ìˆìœ¼ë©´ ì„¤ì •ì„ ê°€ì ¸ì˜´
        if config_manager:
            vs_config = config_manager.get_vector_store_config()
            store_type = vs_config["store_type"]
            persist_directory = vs_config["persist_directory"]

            # # ì„¤ì • ê´€ë¦¬ìì˜ ê°’ì„ ìš°ì„  ì‚¬ìš©
            # if store_type == "auto":
            #     store_type = vs_config["store_type"]
            # if persist_directory is None:
            #     persist_directory = vs_config["persist_directory"]

            # ì¶”ê°€ ì„¤ì • ë³‘í•©
            kwargs.update(
                {
                    k: v
                    for k, v in vs_config.items()
                    if k not in ["store_type", "persist_directory"] and k not in kwargs
                }
            )

        # ìë™ ì €ì¥ì†Œ ì„ íƒ
        if store_type == "auto":
            if _faiss_available:
                store_type = "faiss"
            elif _chromadb_available:
                store_type = "chroma"
            else:
                raise ImportError(
                    "No vector store library available. Install chromadb or faiss-cpu"
                )

        # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì„¤ì •
        if persist_directory is None:
            persist_directory = "./data/processed/vector_store"

        # ì„¤ì • ìƒì„± - ì €ì¥ì†Œë³„ ì„œë¸Œí´ë” ìë™ ìƒì„±
        base_config = VectorStoreConfig(
            store_type=store_type,
            persist_directory=persist_directory,
            collection_name=collection_name,
            **kwargs,
        )

        # ì €ì¥ì†Œë³„ ì „ìš© ë””ë ‰í† ë¦¬ ì‚¬ìš©
        if store_type == "faiss":
            actual_persist_dir = base_config.faiss_directory
        elif store_type == "chroma":
            actual_persist_dir = base_config.chromadb_directory
        elif store_type == "simple":
            actual_persist_dir = base_config.simple_directory
        else:
            actual_persist_dir = persist_directory

        # ì‹¤ì œ ì„¤ì • ê°ì²´ ìƒì„±
        self.config = VectorStoreConfig(
            store_type=store_type,
            persist_directory=actual_persist_dir,
            collection_name=collection_name,
            **kwargs,
        )

        # ë””ë ‰í† ë¦¬ ìƒì„±
        Path(actual_persist_dir).mkdir(parents=True, exist_ok=True)

        # ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
        if store_type == "chroma":
            self.store = ChromaVectorStore(self.config)
        elif store_type == "faiss":
            self.store = FAISSVectorStore(self.config)
        elif store_type == "simple":
            self.store = SimpleVectorStore(self.config)
        else:
            raise ValueError(f"Unsupported store type: {store_type}")

        logger.info(f"âœ… VectorStoreManager initialized: {store_type}")
        logger.info(f"   ğŸ“ Directory: {actual_persist_dir}")

    def load_from_embeddings(
        self,
        embedding_results: Dict[str, List[EmbeddingResult]],
        embeddings_dir: Optional[str] = None,
    ) -> None:
        """EmbeddingResultë¡œë¶€í„° ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• - ìƒˆë¡œìš´ ê²½ë¡œ êµ¬ì¡° ì§€ì›"""

        # ì°¨ì› ê²°ì •
        first_result = next(iter(next(iter(embedding_results.values()))))
        dimension = len(first_result.embedding)

        # ì €ì¥ì†Œ ì´ˆê¸°í™”
        self.store.initialize(dimension)

        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹œë„
        self.store.load()

        logger.info(f"ğŸ“š Loading embeddings into vector store...")
        logger.info(f"   ğŸ“‚ Store type: {self.config.store_type}")
        logger.info(f"   ğŸ“ Directory: {self.config.persist_directory}")

        # íƒ€ì…ë³„ë¡œ ì²˜ë¦¬
        for node_type, results in embedding_results.items():
            if not results:
                continue

            logger.info(f"ğŸ“ Processing {node_type}: {len(results)} embeddings")

            # ë°°ì¹˜ë¡œ ë³€í™˜
            embeddings = np.array([result.embedding for result in results])
            node_ids = [result.node_id for result in results]
            node_types = [result.node_type for result in results]
            texts = [result.text for result in results]
            metadatas = [result.metadata for result in results]

            # ì €ì¥ì†Œì— ì¶”ê°€
            self.store.add_embeddings(
                embeddings=embeddings,
                node_ids=node_ids,
                node_types=node_types,
                texts=texts,
                metadatas=metadatas,
            )

        # ì €ì¥
        self.store.save()

        total_vectors = sum(len(results) for results in embedding_results.values())
        logger.info(f"âœ… Loaded {total_vectors} embeddings into vector store")

        # ì„ë² ë”© ë””ë ‰í† ë¦¬ ì •ë³´ ê¸°ë¡ (ì°¸ì¡°ìš©)
        if embeddings_dir:
            self._save_embeddings_reference(embeddings_dir)

    def load_from_saved_embeddings(
        self,
        embeddings_root_dir: str,
        embeddings_subdir: str = "embeddings",
    ) -> None:
        """ì €ì¥ëœ ì„ë² ë”© íŒŒì¼ë¡œë¶€í„° ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•"""

        embeddings_dir = Path(embeddings_root_dir) / embeddings_subdir

        if not embeddings_dir.exists():
            raise FileNotFoundError(f"Embeddings directory not found: {embeddings_dir}")

        logger.info(f"ğŸ“‚ Loading embeddings from saved files: {embeddings_dir}")

        try:
            # NumPy íŒŒì¼ë“¤ ë¡œë“œ
            embeddings = np.load(embeddings_dir / "embeddings.npy")
            node_ids = np.load(embeddings_dir / "node_ids.npy")
            node_types = np.load(embeddings_dir / "node_types.npy")

            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            with open(
                embeddings_dir / "embeddings_metadata.json", "r", encoding="utf-8"
            ) as f:
                metadata_by_type = json.load(f)

            # ì¸ë±ìŠ¤ íŒŒì¼ ë¡œë“œ
            with open(embeddings_dir / "node_index.json", "r", encoding="utf-8") as f:
                index_data = json.load(f)

            dimension = embeddings.shape[1]
            logger.info(f"ğŸ“ Embedding dimension: {dimension}")

            # ì €ì¥ì†Œ ì´ˆê¸°í™”
            self.store.initialize(dimension)

            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹œë„
            self.store.load()

            # ë©”íƒ€ë°ì´í„° ì¬êµ¬ì„±
            texts = []
            metadatas = []

            # ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ë©”íƒ€ë°ì´í„° ì •ë ¬
            for i, node_id in enumerate(node_ids):
                node_type = node_types[i]

                # í•´ë‹¹ ë…¸ë“œì˜ ë©”íƒ€ë°ì´í„° ì°¾ê¸°
                found_metadata = None
                found_text = ""

                if node_type in metadata_by_type:
                    for item in metadata_by_type[node_type]:
                        if item["node_id"] == node_id:
                            found_metadata = item["metadata"]
                            found_text = item["text"]
                            break

                if found_metadata is None:
                    found_metadata = {"node_type": node_type}

                metadatas.append(found_metadata)
                texts.append(found_text)

            # ì €ì¥ì†Œì— ì¶”ê°€
            self.store.add_embeddings(
                embeddings=embeddings,
                node_ids=node_ids.tolist(),
                node_types=node_types.tolist(),
                texts=texts,
                metadatas=metadatas,
            )

            # ì €ì¥
            self.store.save()

            logger.info(f"âœ… Loaded {len(embeddings)} embeddings from saved files")

        except Exception as e:
            logger.error(f"âŒ Failed to load embeddings from files: {e}")
            raise

    def _save_embeddings_reference(self, embeddings_dir: str) -> None:
        """ì„ë² ë”© ë””ë ‰í† ë¦¬ ì°¸ì¡° ì •ë³´ ì €ì¥"""

        reference_file = (
            Path(self.config.persist_directory) / "embeddings_reference.json"
        )

        reference_data = {
            "embeddings_directory": str(embeddings_dir),
            "vector_store_type": self.config.store_type,
            "created_at": pd.Timestamp.now().isoformat(),
            "store_info": self.get_store_info(),
        }

        try:
            with open(reference_file, "w", encoding="utf-8") as f:
                json.dump(reference_data, f, ensure_ascii=False, indent=2)

            logger.debug(f"ğŸ“ Saved embeddings reference: {reference_file}")

        except Exception as e:
            logger.warning(f"âš ï¸ Failed to save embeddings reference: {e}")

    def get_store_info(self) -> Dict[str, Any]:
        """ì €ì¥ì†Œ ì •ë³´ ë°˜í™˜ - ê²½ë¡œ ì •ë³´ í¬í•¨"""

        base_info = {
            "store_type": self.config.store_type,
            "total_vectors": self.store.total_vectors,
            "dimension": self.store.dimension,
            "is_initialized": self.store.is_initialized,
            "persist_directory": self.config.persist_directory,
            "collection_name": self.config.collection_name,
        }

        # ì„¤ì • ê´€ë¦¬ìê°€ ìˆìœ¼ë©´ ì „ì²´ ê²½ë¡œ êµ¬ì¡° ì •ë³´ ì¶”ê°€
        if self.config_manager:
            paths_config = self.config_manager.config.paths
            base_info["path_structure"] = {
                "vector_store_root": paths_config.vector_store_root,
                "embeddings_dir": paths_config.vector_store.embeddings,  # âœ…
                "faiss_dir": paths_config.vector_store.faiss,  # âœ…
                "chromadb_dir": paths_config.vector_store.chromadb,  # âœ…
                "simple_dir": paths_config.vector_store.simple,  # âœ…
            }

        return base_info

    def migrate_store_type(
        self,
        new_store_type: str,
        keep_original: bool = True,
    ) -> "VectorStoreManager":
        """ë²¡í„° ì €ì¥ì†Œ íƒ€ì… ë§ˆì´ê·¸ë ˆì´ì…˜"""

        logger.info(f"ğŸ”„ Migrating from {self.config.store_type} to {new_store_type}")

        # í˜„ì¬ ë°ì´í„° ì¶”ì¶œ
        if not self.store.is_initialized or self.store.total_vectors == 0:
            raise ValueError("No data to migrate")

        # ìƒˆë¡œìš´ ë§¤ë‹ˆì € ìƒì„±
        new_manager = VectorStoreManager(
            store_type=new_store_type,
            persist_directory=self.config.persist_directory.replace(
                self.config.store_type, new_store_type
            ),
            collection_name=self.config.collection_name,
            config_manager=self.config_manager,
        )

        # ë°ì´í„° ë³µì‚¬ (ì„ë² ë”©ì„ ì§ì ‘ ì¶”ì¶œí•˜ì—¬ ì „ì†¡)
        logger.info("ğŸ“¦ Extracting data from current store...")

        # ëª¨ë“  ë…¸ë“œ ID ìˆ˜ì§‘
        all_node_ids = list(getattr(self.store, "node_id_to_idx", {}).keys()) or list(
            getattr(self.store, "node_ids", [])
        )

        if not all_node_ids:
            raise ValueError("Cannot extract node IDs from current store")

        # ë°°ì¹˜ë¡œ ë°ì´í„° ì¶”ì¶œ ë° ì´ì „
        batch_size = 100
        total_batches = (len(all_node_ids) + batch_size - 1) // batch_size

        for i in range(0, len(all_node_ids), batch_size):
            batch_ids = all_node_ids[i : i + batch_size]

            # í˜„ì¬ ì €ì¥ì†Œì—ì„œ ë°ì´í„° ì¶”ì¶œ
            batch_embeddings = []
            batch_texts = []
            batch_types = []
            batch_metadatas = []

            for node_id in batch_ids:
                # ê° ì €ì¥ì†Œë³„ ë°ì´í„° ì¶”ì¶œ ë°©ë²•
                if hasattr(self.store, "node_texts"):
                    embedding = self.store.get_embedding(node_id)
                    text = self.store.node_texts.get(node_id, "")
                    node_type = self.store.node_types.get(node_id, "unknown")
                    metadata = self.store.node_metadatas.get(node_id, {})

                    if embedding is not None:
                        batch_embeddings.append(embedding)
                        batch_texts.append(text)
                        batch_types.append(node_type)
                        batch_metadatas.append(metadata)

            if batch_embeddings:
                # ìƒˆë¡œìš´ ì €ì¥ì†Œì— ì¶”ê°€
                new_manager.store.add_embeddings(
                    embeddings=np.array(batch_embeddings),
                    node_ids=batch_ids[: len(batch_embeddings)],
                    node_types=batch_types,
                    texts=batch_texts,
                    metadatas=batch_metadatas,
                )

            logger.info(f"ğŸ“¦ Migrated batch {i//batch_size + 1}/{total_batches}")

        # ìƒˆë¡œìš´ ì €ì¥ì†Œ ì €ì¥
        new_manager.store.save()

        logger.info(
            f"âœ… Migration completed: {new_manager.store.total_vectors} vectors"
        )

        return new_manager

    def search_similar_nodes(
        self,
        query_embedding: np.ndarray,
        top_k: int = 10,
        node_types: Optional[List[str]] = None,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[SearchResult]:
        """ìœ ì‚¬ ë…¸ë“œ ê²€ìƒ‰ (ê¸°ì¡´ search ë©”ì„œë“œ ë˜í¼)"""
        return self.store.search(
            query_embedding=query_embedding,
            top_k=top_k,
            node_types=node_types,
            filters=filters,
        )

    def get_node_embedding(self, node_id: str) -> Optional[np.ndarray]:
        """íŠ¹ì • ë…¸ë“œ ì„ë² ë”© ì¡°íšŒ (ê¸°ì¡´ get_embedding ë©”ì„œë“œ ë˜í¼)"""
        return self.store.get_embedding(node_id)


def create_vector_store(
    store_type: str = "auto",
    persist_directory: Optional[str] = None,
    config_manager: Optional["GraphRAGConfigManager"] = None,
    **kwargs,
) -> VectorStoreManager:
    """ë²¡í„° ì €ì¥ì†Œ íŒ©í† ë¦¬ í•¨ìˆ˜ - ì„¤ì • ê´€ë¦¬ì ì§€ì›"""
    return VectorStoreManager(
        store_type=store_type,
        persist_directory=persist_directory,
        config_manager=config_manager,
        **kwargs,
    )


def create_vector_store_from_config(
    config_manager: "GraphRAGConfigManager", store_type: Optional[str] = None, **kwargs
) -> VectorStoreManager:
    """ì„¤ì • ê´€ë¦¬ìë¡œë¶€í„° ë²¡í„° ì €ì¥ì†Œ ìƒì„±"""

    if store_type is None:
        store_type = config_manager.config.vector_store.store_type

    return VectorStoreManager(
        store_type=store_type, config_manager=config_manager, **kwargs
    )


def setup_vector_store_from_embeddings(
    embeddings_root_dir: str,
    config_manager: "GraphRAGConfigManager",
    store_type: Optional[str] = None,
    force_rebuild: bool = False,
) -> VectorStoreManager:
    """ì„ë² ë”© íŒŒì¼ë¡œë¶€í„° ë²¡í„° ì €ì¥ì†Œ ì™„ì „ ìë™ ì„¤ì •"""

    logger.info("ğŸ—ï¸ Setting up vector store from embeddings...")

    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    vector_store = create_vector_store_from_config(
        config_manager=config_manager,
        store_type=store_type,
    )

    # ê¸°ì¡´ ì €ì¥ì†Œ í™•ì¸
    if not force_rebuild and vector_store.store.total_vectors > 0:
        logger.info(
            f"âœ… Existing vector store found with {vector_store.store.total_vectors} vectors"
        )
        return vector_store

    # ì„ë² ë”© íŒŒì¼ì—ì„œ ë¡œë“œ
    try:
        vector_store.load_from_saved_embeddings(embeddings_root_dir)
        logger.info("âœ… Vector store setup completed from saved embeddings")

    except Exception as e:
        logger.error(f"âŒ Failed to setup vector store: {e}")
        raise

    return vector_store


def list_available_stores() -> Dict[str, bool]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë²¡í„° ì €ì¥ì†Œ ëª©ë¡"""
    return {"chromadb": _chromadb_available, "faiss": _faiss_available}


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸ§ª Testing Vector Store Manager...")

    # ì‚¬ìš© ê°€ëŠ¥í•œ ì €ì¥ì†Œ í™•ì¸
    available = list_available_stores()
    print(f"ğŸ“‹ Available stores: {available}")

    if not any(available.values()):
        print("âŒ No vector stores available for testing")
        print("Install with: pip install chromadb faiss-cpu")
        exit(1)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    import tempfile

    with tempfile.TemporaryDirectory() as temp_dir:
        print(f"ğŸ”§ Testing with temp directory: {temp_dir}")

        # í…ŒìŠ¤íŠ¸ ì„ë² ë”© ë°ì´í„°
        test_embeddings = {
            "paper": [
                EmbeddingResult(
                    node_id="paper_1",
                    node_type="paper",
                    text="Machine learning for battery optimization",
                    embedding=np.random.random(384),
                    metadata={"year": "2023", "has_abstract": True},
                ),
                EmbeddingResult(
                    node_id="paper_2",
                    node_type="paper",
                    text="Deep learning approaches to energy management",
                    embedding=np.random.random(384),
                    metadata={"year": "2022", "has_abstract": False},
                ),
            ],
            "author": [
                EmbeddingResult(
                    node_id="author_1",
                    node_type="author",
                    text="ê¹€ì² ìˆ˜ machine learning researcher",
                    embedding=np.random.random(384),
                    metadata={
                        "paper_count": 15,
                        "productivity_type": "Leading Researcher",
                    },
                )
            ],
        }

        # ê° ì €ì¥ì†Œ íƒ€ì… í…ŒìŠ¤íŠ¸
        for store_type, available in available.items():
            if not available:
                continue

            print(f"\nğŸ”§ Testing {store_type.upper()}...")

            try:
                # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                manager = create_vector_store(
                    store_type=store_type, persist_directory=f"{temp_dir}/{store_type}"
                )

                # ì„ë² ë”© ë¡œë“œ
                manager.load_from_embeddings(test_embeddings)

                # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
                query_embedding = np.random.random(384)
                results = manager.search_similar_nodes(
                    query_embedding=query_embedding, top_k=5
                )

                print(f"âœ… {store_type}: {len(results)} search results")
                for result in results[:2]:
                    print(f"   ğŸ“„ {result.node_id}: {result.similarity_score:.3f}")

                # ì •ë³´ ì¶œë ¥
                info = manager.get_store_info()
                print(f"ğŸ“Š Store info: {info}")

            except Exception as e:
                print(f"âŒ {store_type} test failed: {e}")

    print(f"\nâœ… Vector Store Manager tests completed!")
