# faiss_diagnostic.py - FAISS ê²€ìƒ‰ ì‹¤íŒ¨ ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²°

import logging
import traceback
from pathlib import Path
import numpy as np


def diagnose_faiss_issue():
    """FAISS ë¬¸ì œ ìƒì„¸ ì§„ë‹¨"""

    print("ğŸ” FAISS ë¬¸ì œ ì§„ë‹¨ ì‹œì‘")
    print("=" * 80)

    # 1. FAISS ëª¨ë“ˆ ë° GPU ìƒíƒœ í™•ì¸
    print("1ï¸âƒ£ FAISS ëª¨ë“ˆ ìƒíƒœ í™•ì¸")
    print("-" * 40)

    try:
        import faiss

        print(f"âœ… FAISS ë²„ì „: {faiss.__version__}")

        # GPU í™•ì¸
        ngpus = faiss.get_num_gpus()
        print(f"ğŸ® ì‚¬ìš© ê°€ëŠ¥í•œ GPU: {ngpus}ê°œ")

        if ngpus > 0:
            for i in range(ngpus):
                try:
                    gpu_info = faiss.GpuResourcesInfo(i)
                    print(f"   GPU {i}: ì‚¬ìš© ê°€ëŠ¥")
                except:
                    print(f"   GPU {i}: ì‚¬ìš© ë¶ˆê°€")
    except Exception as e:
        print(f"âŒ FAISS ëª¨ë“ˆ ë¬¸ì œ: {e}")
        return False

    # 2. ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ íŒŒì¼ í™•ì¸
    print(f"\n2ï¸âƒ£ FAISS ì¸ë±ìŠ¤ íŒŒì¼ í™•ì¸")
    print("-" * 40)

    index_path = Path("data/processed/vector_store/faiss/faiss/faiss_index.bin")
    metadata_path = Path("data/processed/vector_store/faiss/faiss/faiss_metadata.pkl")

    if not index_path.exists():
        print(f"âŒ FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {index_path}")
        return False

    if not metadata_path.exists():
        print(f"âŒ FAISS ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {metadata_path}")
        return False

    print(
        f"âœ… ì¸ë±ìŠ¤ íŒŒì¼ ì¡´ì¬: {index_path} ({index_path.stat().st_size / 1024 / 1024:.1f} MB)"
    )
    print(f"âœ… ë©”íƒ€ë°ì´í„° íŒŒì¼ ì¡´ì¬: {metadata_path}")

    # 3. FAISS ì¸ë±ìŠ¤ ì§ì ‘ ë¡œë“œ í…ŒìŠ¤íŠ¸
    print(f"\n3ï¸âƒ£ FAISS ì¸ë±ìŠ¤ ì§ì ‘ ë¡œë“œ í…ŒìŠ¤íŠ¸")
    print("-" * 40)

    try:
        # CPUì—ì„œ ì¸ë±ìŠ¤ ë¡œë“œ
        print("ğŸ“‚ CPUì—ì„œ ì¸ë±ìŠ¤ ë¡œë”©...")
        index = faiss.read_index(str(index_path))
        print(f"âœ… ì¸ë±ìŠ¤ ë¡œë“œ ì„±ê³µ")
        print(f"   ë²¡í„° ìˆ˜: {index.ntotal}")
        print(f"   ì°¨ì›: {index.d}")
        print(f"   ì¸ë±ìŠ¤ íƒ€ì…: {type(index)}")

        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        print("\nğŸ“‚ ë©”íƒ€ë°ì´í„° ë¡œë”©...")
        import pickle

        with open(metadata_path, "rb") as f:
            metadata = pickle.load(f)

        print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì„±ê³µ")
        print(f"   ë…¸ë“œ ìˆ˜: {len(metadata.get('node_id_to_idx', {}))}")
        print(f"   ì´ ë²¡í„°: {metadata.get('total_vectors', 0)}")
        print(f"   ì°¨ì›: {metadata.get('dimension', 0)}")

        return index, metadata

    except Exception as e:
        print(f"âŒ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False


def test_faiss_search_directly(index, metadata):
    """FAISS ê²€ìƒ‰ì„ ì§ì ‘ í…ŒìŠ¤íŠ¸"""

    print(f"\n4ï¸âƒ£ FAISS ê²€ìƒ‰ ì§ì ‘ í…ŒìŠ¤íŠ¸")
    print("-" * 40)

    try:
        # í…ŒìŠ¤íŠ¸ìš© ëœë¤ ì¿¼ë¦¬ ë²¡í„° ìƒì„±
        dimension = index.d
        print(f"ğŸ“ ì°¨ì›: {dimension}")

        # ì‹¤ì œ ì„ë² ë”© í•˜ë‚˜ë¥¼ ê°€ì ¸ì™€ì„œ í…ŒìŠ¤íŠ¸
        if index.ntotal > 0:
            print("ğŸ” ê¸°ì¡´ ë²¡í„°ë¡œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
            # ì²« ë²ˆì§¸ ë²¡í„°ë¥¼ ì¿¼ë¦¬ë¡œ ì‚¬ìš©
            test_vector = index.reconstruct(0).reshape(1, -1)

            print(f"   í…ŒìŠ¤íŠ¸ ë²¡í„° í˜•íƒœ: {test_vector.shape}")
            print(f"   í…ŒìŠ¤íŠ¸ ë²¡í„° íƒ€ì…: {test_vector.dtype}")

            # ê²€ìƒ‰ ì‹¤í–‰
            scores, indices = index.search(test_vector, 5)

            print(f"âœ… ê²€ìƒ‰ ì„±ê³µ!")
            print(f"   ë°˜í™˜ëœ ì ìˆ˜: {scores[0]}")
            print(f"   ë°˜í™˜ëœ ì¸ë±ìŠ¤: {indices[0]}")

            # ë…¸ë“œ ID ë§¤í•‘ í™•ì¸
            idx_to_node_id = metadata.get("idx_to_node_id", {})
            for i, idx in enumerate(indices[0]):
                node_id = idx_to_node_id.get(idx, f"unknown_{idx}")
                print(
                    f"   ê²°ê³¼ {i+1}: index={idx}, node_id={node_id}, score={scores[0][i]:.4f}"
                )

            return True
        else:
            print("âŒ ì¸ë±ìŠ¤ì— ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

    except Exception as e:
        print(f"âŒ FAISS ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        traceback.print_exc()

        # ë” ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´
        print(f"\nğŸ” ìƒì„¸ ì—ëŸ¬ ë¶„ì„:")
        print(f"   ì¸ë±ìŠ¤ íƒ€ì…: {type(index)}")
        print(f"   ì¸ë±ìŠ¤ ntotal: {index.ntotal}")
        print(f"   ì¸ë±ìŠ¤ is_trained: {index.is_trained}")

        return False


# faiss_diag.py íŒŒì¼ ìˆ˜ì •
def test_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        # âœ… ìˆ˜ì •ëœ import
        from src.graphrag.embeddings import create_embedding_model

        # get_embedding_model ëŒ€ì‹  create_embedding_model ì‚¬ìš©
        model = create_embedding_model(
            model_name="paraphrase-multilingual-mpnet-base-v2", device="auto"
        )

        # í…ŒìŠ¤íŠ¸ ì„ë² ë”©
        test_text = "This is a test sentence for embedding."
        embedding = model.encode([test_text])

        print(f"âœ… ì„ë² ë”© ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        print(f"   ëª¨ë¸: {model}")
        print(f"   ì„ë² ë”© ì°¨ì›: {embedding.shape}")

        return True

    except Exception as e:
        print(f"âŒ ì„ë² ë”© ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def test_end_to_end_search():
    """ì „ì²´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

    print(f"\n6ï¸âƒ£ ì „ì²´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("-" * 40)

    try:
        from src.graphrag.embeddings.vector_store_manager import VectorStoreManager

        # VectorStoreManager ìƒì„± (CPUë§Œ ì‚¬ìš©)
        print("ğŸ”§ VectorStoreManager ìƒì„± (CPU ëª¨ë“œ)...")
        vector_manager = VectorStoreManager(
            store_type="faiss",
            persist_directory="data/processed/vector_store/faiss/faiss",
            use_gpu=False,  # GPU ë¹„í™œì„±í™”
        )

        # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ
        print("ğŸ“‚ ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ...")
        vector_manager.load()

        print(f"âœ… VectorStoreManager ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ì´ ë²¡í„° ìˆ˜: {vector_manager.total_vectors}")

        # ì„ë² ë”© ëª¨ë¸ë¡œ ì¿¼ë¦¬ ë²¡í„° ìƒì„±
        print(f"\nğŸ¯ ì¿¼ë¦¬ ë²¡í„° ìƒì„±...")
        from src.graphrag.embeddings.embedding_models import get_embedding_model

        model = get_embedding_model("sentence-transformers/all-MiniLM-L6-v2")
        query_embedding = model.encode(["battery machine learning"])[0]

        print(f"   ì¿¼ë¦¬ ì„ë² ë”© í˜•íƒœ: {query_embedding.shape}")

        # ê²€ìƒ‰ ì‹¤í–‰
        print(f"\nğŸ” ê²€ìƒ‰ ì‹¤í–‰...")
        results = vector_manager.search(query_embedding, k=5)

        print(f"âœ… ê²€ìƒ‰ ì„±ê³µ!")
        print(f"   ê²°ê³¼ ìˆ˜: {len(results)}")

        for i, result in enumerate(results):
            print(
                f"   ê²°ê³¼ {i+1}: node_id={result.node_id}, score={result.similarity_score:.4f}"
            )
            print(f"     í…ìŠ¤íŠ¸: {result.text[:100]}...")

        return True

    except Exception as e:
        print(f"âŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False


def fix_faiss_issues():
    """FAISS ë¬¸ì œ ìˆ˜ì • ì‹œë„"""

    print(f"\nğŸ› ï¸ FAISS ë¬¸ì œ ìˆ˜ì • ì‹œë„")
    print("-" * 40)

    try:
        # 1. GPU ì‚¬ìš© ë¹„í™œì„±í™”í•˜ì—¬ ì¬ì‹œë„
        print("1ï¸âƒ£ GPU ë¹„í™œì„±í™”í•˜ì—¬ FAISS í…ŒìŠ¤íŠ¸...")

        from src.graphrag.langchain.custom_retriever import create_graphrag_retriever

        retriever = create_graphrag_retriever(
            unified_graph_path="data/processed/graphs/unified/unified_knowledge_graph.json",
            vector_store_path="data/processed/vector_store",
            embedding_model="sentence-transformers/all-MiniLM-L6-v2",
            max_docs=5,
            min_relevance_score=0.1,
            enable_caching=False,
            # GPU ë¹„í™œì„±í™”
            vector_store_config={"use_gpu": False, "store_type": "faiss"},
        )

        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        docs = retriever.get_relevant_documents("battery")

        if docs and docs[0].metadata.get("total_nodes", 0) > 0:
            print("âœ… GPU ë¹„í™œì„±í™”ë¡œ ë¬¸ì œ í•´ê²°!")
            print(f"   ê²€ìƒ‰ëœ ë…¸ë“œ ìˆ˜: {docs[0].metadata.get('total_nodes', 0)}")
            return "gpu_disabled"
        else:
            print("âŒ GPU ë¹„í™œì„±í™”ë¡œë„ í•´ê²°ë˜ì§€ ì•ŠìŒ")

        # 2. ì„ë² ë”© ì¬ìƒì„± ì‹œë„
        print(f"\n2ï¸âƒ£ ì„ë² ë”© ì¬ìƒì„± ì‹œë„...")
        # ì´ ë¶€ë¶„ì€ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ì œì•ˆë§Œ í•¨
        print("ğŸ’¡ ì„ë² ë”©ì„ ë‹¤ì‹œ ìƒì„±í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print(
            "   python -m src.graphrag.graphrag_pipeline build_embeddings --force-rebuild"
        )

        return "embeddings_rebuild_needed"

    except Exception as e:
        print(f"âŒ ìˆ˜ì • ì‹œë„ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return "failed"


# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸš€ FAISS ë¬¸ì œ ì§„ë‹¨ ì‹œì‘")
    print("=" * 80)

    # 1. ê¸°ë³¸ ì§„ë‹¨
    result = diagnose_faiss_issue()

    if result:
        index, metadata = result

        # 2. ì§ì ‘ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        search_ok = test_faiss_search_directly(index, metadata)

        # 3. ì„ë² ë”© ëª¨ë¸ í…ŒìŠ¤íŠ¸
        embeddings = test_embedding_model()

        # 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
        if search_ok and embeddings is not None:
            pipeline_ok = test_end_to_end_search()

            if not pipeline_ok:
                # 5. ë¬¸ì œ ìˆ˜ì • ì‹œë„
                fix_result = fix_faiss_issues()
                print(f"\nğŸ“‹ ìµœì¢… ì§„ë‹¨ ê²°ê³¼: {fix_result}")
        else:
            # FAISS ë ˆë²¨ì—ì„œ ë¬¸ì œ ë°œìƒ
            fix_result = fix_faiss_issues()
            print(f"\nğŸ“‹ ìµœì¢… ì§„ë‹¨ ê²°ê³¼: {fix_result}")
    else:
        print(f"\nâŒ FAISS ê¸°ë³¸ ì„¤ì •ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ’¡ í•´ê²° ë°©ë²•:")
        print(f"   1. FAISS ì¬ì„¤ì¹˜: pip uninstall faiss-cpu && pip install faiss-cpu")
        print(f"   2. NumPy ë²„ì „ í™•ì¸: pip install 'numpy<2.0'")
        print(f"   3. ì„ë² ë”© ì¬ìƒì„± í•„ìš”")

    print(f"\nâœ… ì§„ë‹¨ ì™„ë£Œ!")
