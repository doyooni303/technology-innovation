# check_source_graphs_abstract.py - ì†ŒìŠ¤ ê·¸ë˜í”„ë“¤ì—ì„œ abstract í™•ì¸

import json
from pathlib import Path
import pandas as pd


def check_all_source_graphs():
    """ëª¨ë“  ì†ŒìŠ¤ ê·¸ë˜í”„ì—ì„œ abstract ì •ë³´ í™•ì¸"""

    print("ğŸ” ëª¨ë“  ì†ŒìŠ¤ ê·¸ë˜í”„ì—ì„œ Abstract í™•ì¸")
    print("=" * 60)

    graphs_dir = Path("data/processed/graphs")

    if not graphs_dir.exists():
        print(f"âŒ ê·¸ë˜í”„ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {graphs_dir}")
        return

    # ê°œë³„ ê·¸ë˜í”„ íŒŒì¼ë“¤ ì°¾ê¸°
    graph_files = list(graphs_dir.glob("*.json"))
    print(f"ğŸ“‚ ë°œê²¬ëœ ê·¸ë˜í”„ íŒŒì¼: {len(graph_files)}ê°œ")

    abstract_summary = {}

    for graph_file in graph_files:
        graph_name = graph_file.stem
        print(f"\nğŸ“„ {graph_name}")
        print("-" * 40)

        try:
            with open(graph_file, "r", encoding="utf-8") as f:
                graph_data = json.load(f)

            nodes = graph_data.get("nodes", [])
            print(f"   ì´ ë…¸ë“œ: {len(nodes)}ê°œ")

            # ë…¼ë¬¸ ë…¸ë“œë§Œ í•„í„°ë§
            paper_nodes = [node for node in nodes if node.get("node_type") == "paper"]

            print(f"   ë…¼ë¬¸ ë…¸ë“œ: {len(paper_nodes)}ê°œ")

            if not paper_nodes:
                print("   âš ï¸ ë…¼ë¬¸ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                continue

            # Abstract í†µê³„
            abstract_fields_found = set()
            papers_with_abstract = 0
            papers_with_content = 0

            # ì²˜ìŒ 5ê°œ ë…¼ë¬¸ ìƒì„¸ ë¶„ì„
            for i, paper in enumerate(paper_nodes[:5]):
                paper_id = paper.get("id", f"paper_{i}")
                title = paper.get("title", "No title")[:50]

                print(f"\n   ğŸ“‹ {paper_id}: {title}...")

                # ëª¨ë“  í•„ë“œ í™•ì¸
                for key, value in paper.items():
                    if key.lower() in ["abstract", "description", "summary", "content"]:
                        abstract_fields_found.add(key)
                        if value and str(value).strip():
                            print(f"     âœ… {key}: {len(str(value))} ë¬¸ì")
                            if key == "abstract":
                                papers_with_abstract += 1
                            papers_with_content += 1
                        else:
                            print(f"     âŒ {key}: ë¹„ì–´ìˆìŒ")

            # ì „ì²´ í†µê³„
            total_with_abstract = sum(
                1 for paper in paper_nodes if paper.get("abstract", "").strip()
            )

            total_with_any_content = sum(
                1
                for paper in paper_nodes
                if any(
                    paper.get(field, "").strip()
                    for field in ["abstract", "description", "summary", "content"]
                )
            )

            abstract_summary[graph_name] = {
                "total_papers": len(paper_nodes),
                "papers_with_abstract": total_with_abstract,
                "papers_with_any_content": total_with_any_content,
                "abstract_fields_found": list(abstract_fields_found),
                "abstract_percentage": (
                    total_with_abstract / len(paper_nodes) * 100 if paper_nodes else 0
                ),
            }

            print(f"\n   ğŸ“Š ì „ì²´ í†µê³„:")
            print(
                f"     Abstract í•„ë“œê°€ ìˆëŠ” ë…¼ë¬¸: {total_with_abstract}/{len(paper_nodes)} ({total_with_abstract/len(paper_nodes)*100:.1f}%)"
            )
            print(
                f"     í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ìˆëŠ” ë…¼ë¬¸: {total_with_any_content}/{len(paper_nodes)}"
            )
            print(f"     ë°œê²¬ëœ í…ìŠ¤íŠ¸ í•„ë“œ: {abstract_fields_found}")

        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
            abstract_summary[graph_name] = {"error": str(e)}

    # ì „ì²´ ìš”ì•½
    print(f"\nğŸ“‹ ì „ì²´ ìš”ì•½")
    print("=" * 60)

    for graph_name, stats in abstract_summary.items():
        if "error" in stats:
            print(f"âŒ {graph_name}: ì˜¤ë¥˜")
        else:
            print(f"ğŸ“„ {graph_name}:")
            print(f"   ë…¼ë¬¸: {stats['total_papers']}ê°œ")
            print(
                f"   Abstract: {stats['papers_with_abstract']}ê°œ ({stats['abstract_percentage']:.1f}%)"
            )
            print(f"   í…ìŠ¤íŠ¸ í•„ë“œ: {stats['abstract_fields_found']}")

    return abstract_summary


def check_raw_metadata():
    """ì›ë³¸ ë©”íƒ€ë°ì´í„°ì—ì„œ abstract í™•ì¸"""

    print(f"\nğŸ” ì›ë³¸ ë©”íƒ€ë°ì´í„°ì—ì„œ Abstract í™•ì¸")
    print("=" * 60)

    # ì›ë³¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ë“¤ í™•ì¸
    metadata_files = [
        "data/processed/raw_extractions/papers_metadata.json",
        "data/processed/raw_extractions/integrated_papers_metadata.json",
        "data/processed/raw_extractions/papers_metadata.csv",
    ]

    for metadata_file in metadata_files:
        file_path = Path(metadata_file)

        if not file_path.exists():
            print(f"âŒ {metadata_file}: íŒŒì¼ ì—†ìŒ")
            continue

        print(f"\nğŸ“„ {file_path.name}")
        print("-" * 40)

        try:
            if file_path.suffix == ".json":
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                if isinstance(data, list):
                    papers = data
                elif isinstance(data, dict):
                    papers = list(data.values())
                else:
                    print("   âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„° í˜•íƒœ")
                    continue

            elif file_path.suffix == ".csv":
                df = pd.read_csv(file_path)
                papers = df.to_dict("records")

            print(f"   ì´ ë…¼ë¬¸: {len(papers)}ê°œ")

            # Abstract ê´€ë ¨ í•„ë“œ í™•ì¸
            abstract_fields = set()
            papers_with_abstract = 0

            for paper in papers[:5]:  # ì²˜ìŒ 5ê°œë§Œ ìƒì„¸ í™•ì¸
                print(f"\n   ğŸ“‹ ìƒ˜í”Œ: {paper.get('title', 'No title')[:50]}...")

                for key, value in paper.items():
                    if "abstract" in key.lower() or key.lower() in [
                        "description",
                        "summary",
                        "content",
                    ]:
                        abstract_fields.add(key)
                        if value and str(value).strip():
                            print(f"     âœ… {key}: {len(str(value))} ë¬¸ì")
                        else:
                            print(f"     âŒ {key}: ë¹„ì–´ìˆìŒ")

            # ì „ì²´ í†µê³„
            for paper in papers:
                if any(
                    paper.get(field, "").strip()
                    for field in ["abstract", "description", "summary", "content"]
                    if field in paper
                ):
                    papers_with_abstract += 1

            print(f"\n   ğŸ“Š í†µê³„:")
            print(f"     Abstract ê´€ë ¨ í•„ë“œ: {abstract_fields}")
            print(
                f"     í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ìˆëŠ” ë…¼ë¬¸: {papers_with_abstract}/{len(papers)} ({papers_with_abstract/len(papers)*100:.1f}%)"
            )

        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")


def recommend_next_steps():
    """ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ"""

    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ")
    print("=" * 60)

    print(f"1. ğŸ“Š ì›ë³¸ ë°ì´í„° í™•ì¸:")
    print(f"   - PDFì—ì„œ abstract ì¶”ì¶œì´ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸")
    print(f"   - bibtex íŒŒì¼ì— abstract ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸")

    print(f"\n2. ğŸ› ï¸ ê·¸ë˜í”„ êµ¬ì¶• ìˆ˜ì •:")
    print(f"   - unified_graph_builder.pyì— ìœ„ì˜ ìˆ˜ì •ì‚¬í•­ ì ìš©")
    print(f"   - ê°œë³„ ê·¸ë˜í”„ ë¹Œë”ë“¤ë„ abstract í¬í•¨í•˜ë„ë¡ ìˆ˜ì •")

    print(f"\n3. ğŸ”„ ì¬êµ¬ì¶•:")
    print(f"   - ê·¸ë˜í”„ ì¬êµ¬ì¶•: python -m src.graphrag.unified_graph_builder")
    print(
        f"   - ì„ë² ë”© ì¬ìƒì„±: python -m src.graphrag.graphrag_pipeline build_embeddings --force-rebuild"
    )

    print(f"\n4. âœ… ê²€ì¦:")
    print(f"   - python check_graph_abstract.py")
    print(f"   - python retrieval_debug_with_logging.py")


if __name__ == "__main__":
    # 1. ì†ŒìŠ¤ ê·¸ë˜í”„ í™•ì¸
    summary = check_all_source_graphs()

    # 2. ì›ë³¸ ë©”íƒ€ë°ì´í„° í™•ì¸
    check_raw_metadata()

    # 3. ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ
    recommend_next_steps()
