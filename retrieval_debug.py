# retrieval_debug.py - Retrieval ê³¼ì • ìƒì„¸ ë””ë²„ê¹…

import logging
from pathlib import Path

# GraphRAG ì»´í¬ë„ŒíŠ¸ë“¤ ì§ì ‘ ìƒì„±
from src.graphrag.langchain.custom_retriever import create_graphrag_retriever

# 1. ìƒì„¸ ë¡œê¹… í™œì„±í™”
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("graphrag")
logger.setLevel(logging.DEBUG)


def debug_retrieval_process(question: str):
    """Retrieval ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë””ë²„ê¹…"""

    print(f"ğŸ” ë””ë²„ê¹… ì§ˆë¬¸: {question}")
    print("=" * 80)

    try:
        # Retriever ìƒì„±
        retriever = create_graphrag_retriever(
            unified_graph_path="data/processed/graphs/unified/unified_knowledge_graph.json",
            vector_store_path="data/processed/vector_store",
            embedding_model="auto",
            max_docs=10,
            min_relevance_score=0.3,  # ë‚®ì¶°ì„œ ë” ë§ì€ ê²°ê³¼ í™•ì¸
            enable_caching=False,  # ìºì‹œ ë¹„í™œì„±í™”
        )

        print("âœ… Retriever ìƒì„± ì™„ë£Œ")

        # 1ë‹¨ê³„: ì›ì‹œ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
        print("\nğŸ“‹ 1ë‹¨ê³„: ì›ì‹œ ê²€ìƒ‰ ê²°ê³¼")
        documents = retriever.get_relevant_documents(question)
        print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(documents)}")

        for i, doc in enumerate(documents):
            print(f"\n--- ë¬¸ì„œ {i+1} ---")
            print(f"ë‚´ìš© (ì• 200ì): {doc.page_content[:200]}...")
            print(f"ë©”íƒ€ë°ì´í„°: {doc.metadata}")

            # ê´€ë ¨ì„± ì ìˆ˜ í™•ì¸
            if "confidence_score" in doc.metadata:
                print(f"ì‹ ë¢°ë„ ì ìˆ˜: {doc.metadata['confidence_score']}")

        # 2ë‹¨ê³„: Context Serialization ê²°ê³¼ í™•ì¸
        print(f"\nğŸ“ 2ë‹¨ê³„: ì§ë ¬í™”ëœ ì»¨í…ìŠ¤íŠ¸")
        if documents:
            main_doc = documents[0]  # ë©”ì¸ ë¬¸ì„œ
            print(f"ì§ë ¬í™”ëœ í…ìŠ¤íŠ¸:\n{main_doc.page_content}")
        else:
            print("âŒ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!")

        # 3ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ìƒì„± ê³¼ì • í™•ì¸
        print(f"\nğŸ¯ 3ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ë³€í™˜ ê³¼ì •")

        # ì»¨í…ìŠ¤íŠ¸ ê²°í•©
        context = "\n\n".join([doc.page_content for doc in documents])
        print(f"ê²°í•©ëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)} ë¬¸ì")
        print(f"ê²°í•©ëœ ì»¨í…ìŠ¤íŠ¸ (ì• 300ì):\n{context[:300]}...")

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©
        from src.graphrag.langchain.prompt_templates import GraphRAGPromptTemplates

        prompt_builder = GraphRAGPromptTemplates()
        prompt_template = prompt_builder.create_langchain_prompt()

        # í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
        formatted_prompt = prompt_template.format(context=context, question=question)

        print(f"\nğŸ“„ ìµœì¢… í”„ë¡¬í”„íŠ¸:")
        print("=" * 50)
        print(formatted_prompt)
        print("=" * 50)

        return {
            "documents": documents,
            "context": context,
            "formatted_prompt": formatted_prompt,
        }

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()
        return None


def debug_vector_search_threshold(question: str):
    """ë²¡í„° ê²€ìƒ‰ ì„ê³„ê°’ í…ŒìŠ¤íŠ¸"""

    print(f"\nğŸ¯ ë²¡í„° ê²€ìƒ‰ ì„ê³„ê°’ í…ŒìŠ¤íŠ¸: {question}")

    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]

    for threshold in thresholds:
        # try:
        retriever = create_graphrag_retriever(
            unified_graph_path="data/processed/graphs/unified/unified_knowledge_graph.json",
            vector_store_path="data/processed/vector_store",
            embedding_model="auto",
            max_docs=5,
            min_relevance_score=threshold,
            enable_caching=False,
        )

        docs = retriever.get_relevant_documents(question)
        print(f"ì„ê³„ê°’ {threshold}: {len(docs)}ê°œ ë¬¸ì„œ")

        if docs:
            best_score = docs[0].metadata.get("confidence_score", 0.0)
            print(f"   ìµœê³  ì ìˆ˜: {best_score:.3f}")

    # except Exception as e:
    #     print(f"ì„ê³„ê°’ {threshold}: ì—ëŸ¬ - {e}")


def debug_embedding_similarity(question: str):
    from src.graphrag.embeddings.embedding_models import create_embedding_model

    model = create_embedding_model("auto")  # ì˜¬ë°”ë¥¸ í•¨ìˆ˜

    # ì§ˆë¬¸ ì„ë² ë”©
    question_embedding = model.encode([question])
    print(f"ì§ˆë¬¸ ì„ë² ë”© ì°¨ì›: {question_embedding.shape}")

    # ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ìƒìœ„ ê²°ê³¼ ì§ì ‘ ê²€ìƒ‰
    from src.graphrag.embeddings.vector_store_manager import VectorStoreManager

    vector_manager = VectorStoreManager(
        "faiss", "data/processed/vector_store/faiss/faiss"
    )

    # ìƒìœ„ 20ê°œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    results = vector_manager.search(question_embedding[0], k=20)

    print(f"ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")

    for i, result in enumerate(results[:5]):
        print(
            f"ê²°ê³¼ {i+1}: node_id={result.node_id}, score={result.similarity_score:.3f}"
        )

    # except Exception as e:
    #     print(f"âŒ ì„ë² ë”© í…ŒìŠ¤íŠ¸ ì—ëŸ¬: {e}")
    #     import traceback

    #     traceback.print_exc()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    question = "What machine learning techniques are used for battery SoC prediction?"

    print("ğŸš€ GraphRAG Retrieval ë””ë²„ê¹… ì‹œì‘")
    print("=" * 80)

    # 1. ì „ì²´ retrieval ê³¼ì • ë””ë²„ê¹…
    result = debug_retrieval_process(question)

    # 2. ì„ê³„ê°’ í…ŒìŠ¤íŠ¸
    debug_vector_search_threshold(question)

    # 3. ì„ë² ë”© ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
    debug_embedding_similarity(question)

    print("\nâœ… ë””ë²„ê¹… ì™„ë£Œ!")
