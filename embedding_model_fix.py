# embedding_model_fix.py - ì„ë² ë”© ëª¨ë¸ ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°

import json
import pickle
import numpy as np
from pathlib import Path


def diagnose_embedding_model_mismatch():
    """ì„ë² ë”© ëª¨ë¸ ë¶ˆì¼ì¹˜ ë¬¸ì œ ì§„ë‹¨"""

    print("ğŸ” ì„ë² ë”© ëª¨ë¸ ë¶ˆì¼ì¹˜ ë¬¸ì œ ì§„ë‹¨")
    print("=" * 60)

    # 1. ì €ì¥ëœ ì„ë² ë”© ë©”íƒ€ë°ì´í„° í™•ì¸
    metadata_path = Path("data/processed/vector_store/faiss/faiss/faiss_metadata.pkl")

    if metadata_path.exists():
        with open(metadata_path, "rb") as f:
            metadata = pickle.load(f)

        print("ğŸ“Š ì €ì¥ëœ ì„ë² ë”© ì •ë³´:")
        print(f"   ì°¨ì›: {metadata.get('dimension', 'Unknown')}")
        print(f"   ì´ ë²¡í„°: {metadata.get('total_vectors', 'Unknown')}")
        print(f"   ë…¸ë“œ ìˆ˜: {len(metadata.get('node_id_to_idx', {}))}")

        # ì²« ë²ˆì§¸ ë…¸ë“œì˜ ì„ë² ë”© í™•ì¸
        if metadata.get("node_metadatas"):
            first_node_id = list(metadata["node_metadatas"].keys())[0]
            print(f"   ì²« ë²ˆì§¸ ë…¸ë“œ: {first_node_id}")
            print(f"   ë©”íƒ€ë°ì´í„°: {metadata['node_metadatas'][first_node_id]}")

    # 2. ì„ë² ë”© ì›ë³¸ íŒŒì¼ë“¤ í™•ì¸
    embeddings_dir = Path("data/processed/vector_store/embeddings")

    if embeddings_dir.exists():
        print(f"\nğŸ“‚ ì›ë³¸ ì„ë² ë”© íŒŒì¼ë“¤:")

        embedding_files = list(embeddings_dir.glob("*.npy"))
        json_files = list(embeddings_dir.glob("*.json"))

        print(f"   NumPy íŒŒì¼: {len(embedding_files)}ê°œ")
        print(f"   JSON íŒŒì¼: {len(json_files)}ê°œ")

        # ì²« ë²ˆì§¸ ì„ë² ë”© íŒŒì¼ ìƒ˜í”Œ í™•ì¸
        if embedding_files:
            sample_file = embedding_files[0]
            embeddings = np.load(sample_file)
            print(f"   ìƒ˜í”Œ ì„ë² ë”© í˜•íƒœ: {embeddings.shape}")
            print(f"   ìƒ˜í”Œ íŒŒì¼: {sample_file.name}")

            return embeddings.shape[1]  # ì°¨ì› ë°˜í™˜

    return None


def test_current_embedding_model():
    """í˜„ì¬ ì„ë² ë”© ëª¨ë¸ì˜ ì°¨ì› í™•ì¸"""

    print(f"\nğŸ¤– í˜„ì¬ ì„ë² ë”© ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("-" * 40)

    try:
        # SentenceTransformers ì§ì ‘ í…ŒìŠ¤íŠ¸
        print("ğŸ“¥ SentenceTransformers ëª¨ë¸ ë¡œë“œ...")
        from sentence_transformers import SentenceTransformer

        model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

        test_text = "battery machine learning"
        embedding = model.encode([test_text])

        print(f"âœ… í˜„ì¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        print(f"   ëª¨ë¸: sentence-transformers/all-MiniLM-L6-v2")
        print(f"   ì°¨ì›: {embedding.shape[1]}")
        print(f"   í…ŒìŠ¤íŠ¸ ì„ë² ë”© í˜•íƒœ: {embedding.shape}")

        return embedding.shape[1]

    except Exception as e:
        print(f"âŒ í˜„ì¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None


def fix_embedding_model_mismatch():
    """ì„ë² ë”© ëª¨ë¸ ë¶ˆì¼ì¹˜ í•´ê²°"""

    print(f"\nğŸ› ï¸ ì„ë² ë”© ëª¨ë¸ ë¶ˆì¼ì¹˜ í•´ê²°")
    print("-" * 40)

    # ì €ì¥ëœ ì°¨ì›ê³¼ í˜„ì¬ ëª¨ë¸ ì°¨ì› í™•ì¸
    stored_dim = diagnose_embedding_model_mismatch()
    current_dim = test_current_embedding_model()

    if stored_dim and current_dim:
        print(f"\nğŸ“Š ì°¨ì› ë¹„êµ:")
        print(f"   ì €ì¥ëœ ì„ë² ë”© ì°¨ì›: {stored_dim}")
        print(f"   í˜„ì¬ ëª¨ë¸ ì°¨ì›: {current_dim}")

        if stored_dim != current_dim:
            print(f"\nâŒ ì°¨ì› ë¶ˆì¼ì¹˜ ë°œê²¬!")
            print(f"   í•´ê²° ë°©ë²•ë“¤:")

            # ë°©ë²• 1: ì˜¬ë°”ë¥¸ ëª¨ë¸ë¡œ ë³€ê²½
            if stored_dim == 768:
                print(f"\nğŸ¯ ë°©ë²• 1: ì €ì¥ëœ ì„ë² ë”©ê³¼ í˜¸í™˜ë˜ëŠ” ëª¨ë¸ ì‚¬ìš©")
                print(f"   ì¶”ì²œ ëª¨ë¸: paraphrase-multilingual-mpnet-base-v2 (768ì°¨ì›)")
                return "use_768_model"

            elif stored_dim == 384:
                print(f"\nğŸ¯ ë°©ë²• 1: í˜„ì¬ ëª¨ë¸ì´ ì˜¬ë°”ë¦„")
                print(f"   ì €ì¥ëœ ì„ë² ë”©ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŒ")
                return "current_model_correct"

            # ë°©ë²• 2: ì„ë² ë”© ì¬ìƒì„±
            print(f"\nğŸ¯ ë°©ë²• 2: ì„ë² ë”© ì¬ìƒì„± (í™•ì‹¤í•œ í•´ê²°)")
            print(f"   ëª…ë ¹ì–´: python rebuild_embeddings.py")

            return "rebuild_needed"
        else:
            print(f"\nâœ… ì°¨ì›ì´ ì¼ì¹˜í•©ë‹ˆë‹¤!")
            print(f"   ë‹¤ë¥¸ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return "dimensions_match"

    return "unknown"


def create_compatible_retriever():
    """í˜¸í™˜ ê°€ëŠ¥í•œ retriever ìƒì„±"""

    print(f"\nğŸ”§ í˜¸í™˜ ê°€ëŠ¥í•œ Retriever ìƒì„±")
    print("-" * 40)

    # 768ì°¨ì› ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
    try:
        from src.graphrag.langchain.custom_retriever import create_graphrag_retriever

        print("ğŸ§ª 768ì°¨ì› ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸...")
        retriever = create_graphrag_retriever(
            unified_graph_path="data/processed/graphs/unified/unified_knowledge_graph.json",
            vector_store_path="data/processed/vector_store",
            embedding_model="paraphrase-multilingual-mpnet-base-v2",  # 768ì°¨ì›
            max_docs=5,
            min_relevance_score=0.1,
            enable_caching=False,
        )

        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        docs = retriever.get_relevant_documents("battery machine learning")

        if docs and docs[0].metadata.get("total_nodes", 0) > 0:
            print("âœ… 768ì°¨ì› ëª¨ë¸ë¡œ ì„±ê³µ!")
            print(f"   ê²€ìƒ‰ëœ ë…¸ë“œ ìˆ˜: {docs[0].metadata.get('total_nodes')}")
            return "768_model_works"
        else:
            print("âŒ 768ì°¨ì› ëª¨ë¸ë¡œë„ ì‹¤íŒ¨")

    except Exception as e:
        print(f"âŒ 768ì°¨ì› ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    # 384ì°¨ì› ëª¨ë¸ë¡œ ì¬ì‹œë„
    try:
        print("\nğŸ§ª 384ì°¨ì› ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸...")
        retriever = create_graphrag_retriever(
            unified_graph_path="data/processed/graphs/unified/unified_knowledge_graph.json",
            vector_store_path="data/processed/vector_store",
            embedding_model="all-MiniLM-L6-v2",  # 384ì°¨ì›
            max_docs=5,
            min_relevance_score=0.1,
            enable_caching=False,
        )

        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        docs = retriever.get_relevant_documents("battery machine learning")

        if docs and docs[0].metadata.get("total_nodes", 0) > 0:
            print("âœ… 384ì°¨ì› ëª¨ë¸ë¡œ ì„±ê³µ!")
            print(f"   ê²€ìƒ‰ëœ ë…¸ë“œ ìˆ˜: {docs[0].metadata.get('total_nodes')}")
            return "384_model_works"
        else:
            print("âŒ 384ì°¨ì› ëª¨ë¸ë¡œë„ ì‹¤íŒ¨")

    except Exception as e:
        print(f"âŒ 384ì°¨ì› ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    return "all_failed"


def quick_rebuild_embeddings():
    """ë¹ ë¥¸ ì„ë² ë”© ì¬ìƒì„±"""

    print(f"\nğŸš€ ë¹ ë¥¸ ì„ë² ë”© ì¬ìƒì„±")
    print("-" * 40)

    try:
        # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë°±ì—…
        import shutil

        vector_store_path = Path("data/processed/vector_store")
        backup_path = Path("data/processed/vector_store_backup")

        if vector_store_path.exists():
            print("ğŸ“¦ ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë°±ì—…...")
            if backup_path.exists():
                shutil.rmtree(backup_path)
            shutil.copytree(vector_store_path, backup_path)
            print(f"   ë°±ì—… ì™„ë£Œ: {backup_path}")

        # FAISS ì¸ë±ìŠ¤ë§Œ ì‚­ì œ (ì›ë³¸ ì„ë² ë”©ì€ ìœ ì§€)
        faiss_path = vector_store_path / "faiss"
        if faiss_path.exists():
            print("ğŸ—‘ï¸ ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ì‚­ì œ...")
            shutil.rmtree(faiss_path)

        print("ğŸ’¡ ì´ì œ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   1. ì„¤ì • íŒŒì¼ì—ì„œ ì„ë² ë”© ëª¨ë¸ í™•ì¸")
        print("   2. python -m src.graphrag.graphrag_pipeline build_embeddings")

        return True

    except Exception as e:
        print(f"âŒ ì¬ìƒì„± ì¤€ë¹„ ì‹¤íŒ¨: {e}")
        return False


# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸš€ ì„ë² ë”© ëª¨ë¸ ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²° ì‹œì‘")
    print("=" * 60)

    # 1. ë¬¸ì œ ì§„ë‹¨
    issue_type = fix_embedding_model_mismatch()

    # 2. í˜¸í™˜ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    if issue_type in ["use_768_model", "rebuild_needed"]:
        working_model = create_compatible_retriever()

        if working_model in ["768_model_works", "384_model_works"]:
            print(f"\nâœ… í•´ê²°ì±… ë°œê²¬!")

            if working_model == "768_model_works":
                print(f"ğŸ“ graphrag_config.yamlì—ì„œ ë‹¤ìŒìœ¼ë¡œ ë³€ê²½:")
                print(f"   model_name: paraphrase-multilingual-mpnet-base-v2")
            elif working_model == "384_model_works":
                print(f"ğŸ“ graphrag_config.yamlì—ì„œ ë‹¤ìŒìœ¼ë¡œ ë³€ê²½:")
                print(f"   model_name: all-MiniLM-L6-v2")

        else:
            print(f"\nğŸ”„ ì„ë² ë”© ì¬ìƒì„±ì´ í•„ìš”í•©ë‹ˆë‹¤")
            quick_rebuild_embeddings()

    print(f"\nâœ… ì§„ë‹¨ ì™„ë£Œ!")
